{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Parameters to be tuned:\\n- Output file name, if you don't update the name manually the previous file won't be deleted. New data will be appended to the end of the file instead.\\n- Flag that enables training data to be saved, a False flag will decrease running time significantly.\\n- Flag that enables laplacian related data to be saved.\\n- Number of simulations per layer.\\n- Total number of bits that will be flipped randomly from any weight in each layer.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple, List\n",
    "\n",
    "def evaluate_model(interpreter: tf.lite.Interpreter, test_images, test_labels) -> Tuple[float, float]:\n",
    "    \"\"\" Evaluate TFLite Model:\n",
    "    -\n",
    "    Receives the interpreter and returns a tuple of loss and accuracy.\n",
    "    \"\"\"\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    predictions = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "        test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        predictions.append(np.copy(output()[0]))\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    predictions = np.array(predictions)\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()(test_labels, predictions)\n",
    "\n",
    "    loss = scce.numpy()\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return loss, accuracy\n",
    "\n",
    "def prob_mass_gen(bits : int) -> Tuple[List[int], List[float]]:\n",
    "    \"\"\" Discrete triangular distribution\n",
    "    -\n",
    "    - Receives the number of bits and calculates the probability mass function \"\"\"\n",
    "    values = np.arange(0, bits)\n",
    "    n = len(values)\n",
    "    p_max = 2/n\n",
    "    m_max = p_max/(n - 1)\n",
    "    # Probability calculation\n",
    "    p = p_max * 1.0\n",
    "    m = 2/(n - 1)*(p - 1/n)\n",
    "    probabilities = [p + m*(i - values[-1]) for i in values]\n",
    "    return values, probabilities\n",
    "\n",
    "def random_bit_flipper(value : int) -> Tuple[int, int]:\n",
    "    \"\"\" Random bit flipper \n",
    "    -\n",
    "    Obtains a value and flips one bit at a random position according to a triangular distribution.\n",
    "    - All values are in 8 bits, MSB have higher probability of getting flipped\n",
    "    - It is assumed value is a signed 8 bit number \"\"\"\n",
    "    bits, probs = prob_mass_gen(8)\n",
    "    bit_pos = np.random.choice(bits, p = probs)\n",
    "    # Negative 2 Complement conversion\n",
    "    if value < 0:\n",
    "        value = (-value ^ 0xFF) + 1\n",
    "    flip_mask = 1 << bit_pos\n",
    "    flipped_value = value ^ flip_mask\n",
    "    # Negative back conversion 2 Complement\n",
    "    if flipped_value >= 128:\n",
    "        flipped_value = -((flipped_value ^ 0xFF) + 1)\n",
    "    return bit_pos, flipped_value\n",
    "\n",
    "def random_bit_flipper_uniform(value : int) -> Tuple[int, int]:\n",
    "    \"\"\" Random bit flipper with uniform distribution\n",
    "    -\n",
    "    Obtains a value and flips one bit at a random position according to a uniform distribution.\n",
    "    - All values are in 8 bits, MSB have higher probability of getting flipped\n",
    "    - It is assumed value is a signed 8 bit number \"\"\"\n",
    "    bit_pos = np.random.randint(8)\n",
    "    # Negative 2 Complement conversion\n",
    "    if value < 0:\n",
    "        value = (-value ^ 0xFF) + 1\n",
    "    flip_mask = 1 << bit_pos\n",
    "    flipped_value = value ^ flip_mask\n",
    "    # Negative back conversion 2 Complement\n",
    "    if flipped_value >= 128:\n",
    "        flipped_value = -((flipped_value ^ 0xFF) + 1)\n",
    "    return bit_pos, flipped_value\n",
    "\n",
    "\"\"\" Parameters to be tuned:\n",
    "- Output file name, if you don't update the name manually the previous file won't be deleted. New data will be appended to the end of the file instead.\n",
    "- Flag that enables training data to be saved, a False flag will decrease running time significantly.\n",
    "- Flag that enables laplacian related data to be saved.\n",
    "- Number of simulations per layer.\n",
    "- Total number of bits that will be flipped randomly from any weight in each layer.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE_NAME = 'Performance_Multiple_5.csv'\n",
    "SAVE_TRAINING_PERFORMANCE_FLAG = False\n",
    "SAVE_LAPLACIAN_DATA_FLAG = True\n",
    "N_SIMULATIONS_PER_LAYER = 1\n",
    "N_BITS_TO_FLIP = 10\n",
    "\n",
    "MODELS_DIR = \"./model/\"\n",
    "LOAD_PATH_Q_AWARE = MODELS_DIR + \"model_q_aware_final_01\"\n",
    "LOAD_TFLITE_PATH = MODELS_DIR + 'tflite_final_01.tflite'\n",
    "SAVE_NEW_TFLITE_PATH = MODELS_DIR + 'new_tflite_flip_01.tflite'\n",
    "OUTPUTS_DIR = \"./outputs/\"\n",
    "SAVE_DATA_PATH = OUTPUTS_DIR + SAVE_FILE_NAME\n",
    "\n",
    "if not os.path.exists(OUTPUTS_DIR):\n",
    "    os.mkdir(OUTPUTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2891 - accuracy: 0.9115\n",
      "Q Aware model test accuracy :  91.15%\n",
      "Q Aware model test loss:  0.2890910804271698\n",
      "TFLite model test accuracy: 91.17%\n",
      "TFLite model test loss:  0.3396423\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Load Q Aware model\n",
    "q_aware_model : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tf.keras.models.load_model(LOAD_PATH_Q_AWARE)\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(LOAD_TFLITE_PATH)\n",
    "\n",
    "# Evaluate accuracy of both models in test set\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Q Aware model test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))\n",
    "print('Q Aware model test loss: ', q_aware_test_loss)\n",
    "interpreter.allocate_tensors()\n",
    "tflite_test_loss, tflite_test_accuracy = evaluate_model(interpreter, test_images, test_labels)\n",
    "print('TFLite model test accuracy:', \"{:0.2%}\".format(tflite_test_accuracy))\n",
    "print('TFLite model test loss: ', tflite_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Aware model summary\n",
      "0 input_1 0 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "1 quantize_layer 3 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "2 quant_conv2d 7 input (None, 28, 28, 1) output (None, 24, 24, 32)\n",
      "3 quant_max_pooling2d 1 input (None, 24, 24, 32) output (None, 12, 12, 32)\n",
      "4 quant_conv2d_1 7 input (None, 12, 12, 32) output (None, 8, 8, 64)\n",
      "5 quant_max_pooling2d_1 1 input (None, 8, 8, 64) output (None, 4, 4, 64)\n",
      "6 quant_conv2d_2 7 input (None, 4, 4, 64) output (None, 2, 2, 96)\n",
      "7 quant_max_pooling2d_2 1 input (None, 2, 2, 96) output (None, 1, 1, 96)\n",
      "8 quant_flatten 1 input (None, 1, 1, 96) output (None, 96)\n",
      "9 quant_dense_last 7 input (None, 96) output (None, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Q Aware model summary\")\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    print(i, layer.name, len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/kernel:0\n",
      "conv2d/bias:0\n",
      "quant_conv2d/optimizer_step:0\n",
      "quant_conv2d/kernel_min:0\n",
      "quant_conv2d/kernel_max:0\n",
      "quant_conv2d/post_activation_min:0\n",
      "quant_conv2d/post_activation_max:0\n",
      "[-3.9335735, 4.380244]\n"
     ]
    }
   ],
   "source": [
    "TARGET_LAYER = 2\n",
    "for variable in q_aware_model.layers[TARGET_LAYER].variables:\n",
    "    print(variable.name)\n",
    "vars = [var.numpy() for var in q_aware_model.layers[TARGET_LAYER].non_trainable_variables[-2:]]\n",
    "print(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable\n",
      "2 quant_conv2d conv2d/kernel:0\n",
      "2 quant_conv2d conv2d/bias:0\n",
      "4 quant_conv2d_1 conv2d_1/kernel:0\n",
      "4 quant_conv2d_1 conv2d_1/bias:0\n",
      "6 quant_conv2d_2 conv2d_2/kernel:0\n",
      "6 quant_conv2d_2 conv2d_2/bias:0\n",
      "9 quant_dense_last dense_last/kernel:0\n",
      "9 quant_dense_last dense_last/bias:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainable\")\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non trainable\n",
      "1 quantize_layer quantize_layer/quantize_layer_min:0\n",
      "1 quantize_layer quantize_layer/quantize_layer_max:0\n",
      "1 quantize_layer quantize_layer/optimizer_step:0\n",
      "2 quant_conv2d quant_conv2d/optimizer_step:0\n",
      "2 quant_conv2d quant_conv2d/kernel_min:0\n",
      "2 quant_conv2d quant_conv2d/kernel_max:0\n",
      "2 quant_conv2d quant_conv2d/post_activation_min:0\n",
      "2 quant_conv2d quant_conv2d/post_activation_max:0\n",
      "3 quant_max_pooling2d quant_max_pooling2d/optimizer_step:0\n",
      "4 quant_conv2d_1 quant_conv2d_1/optimizer_step:0\n",
      "4 quant_conv2d_1 quant_conv2d_1/kernel_min:0\n",
      "4 quant_conv2d_1 quant_conv2d_1/kernel_max:0\n",
      "4 quant_conv2d_1 quant_conv2d_1/post_activation_min:0\n",
      "4 quant_conv2d_1 quant_conv2d_1/post_activation_max:0\n",
      "5 quant_max_pooling2d_1 quant_max_pooling2d_1/optimizer_step:0\n",
      "6 quant_conv2d_2 quant_conv2d_2/optimizer_step:0\n",
      "6 quant_conv2d_2 quant_conv2d_2/kernel_min:0\n",
      "6 quant_conv2d_2 quant_conv2d_2/kernel_max:0\n",
      "6 quant_conv2d_2 quant_conv2d_2/post_activation_min:0\n",
      "6 quant_conv2d_2 quant_conv2d_2/post_activation_max:0\n",
      "7 quant_max_pooling2d_2 quant_max_pooling2d_2/optimizer_step:0\n",
      "8 quant_flatten quant_flatten/optimizer_step:0\n",
      "9 quant_dense_last quant_dense_last/optimizer_step:0\n",
      "9 quant_dense_last quant_dense_last/kernel_min:0\n",
      "9 quant_dense_last quant_dense_last/kernel_max:0\n",
      "9 quant_dense_last quant_dense_last/pre_activation_min:0\n",
      "9 quant_dense_last quant_dense_last/pre_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Non trainable\")\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu')(input_layer)\n",
    "\n",
    "input_layer_2 = tf.keras.layers.Input(shape = (24, 24, 32))\n",
    "pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(input_layer_2)\n",
    "conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu')(pool_1)\n",
    "pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu')(pool_2)\n",
    "pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\")(flat_1)\n",
    "\n",
    "nq_model_part1 = tf.keras.models.Model(inputs = input_layer, outputs = conv_1)\n",
    "nq_model_part2 = tf.keras.models.Model(inputs = input_layer_2, outputs = dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantification of values\n",
    "BIT_WIDTH = 8\n",
    "quantized_and_dequantized = OrderedDict()\n",
    "quantized = OrderedDict()\n",
    "layer_index_list = []\n",
    "keys_list = []\n",
    "layers_shapes = []\n",
    "\n",
    "layer : tfmot.quantization.keras.QuantizeWrapperV2\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    quantizer : tfmot.quantization.keras.quantizers.Quantizer\n",
    "    weight : tf.Variable\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "\n",
    "            key = weight.name[:-2]\n",
    "            layer_index_list.append(i)\n",
    "            keys_list.append(key)\n",
    "            layers_shapes.append(weight.numpy().shape)\n",
    "            quantized_and_dequantized[key] = quantizer(inputs = weight, training = False, weights = quantizer_vars)\n",
    "            quantized[key] = np.round(quantized_and_dequantized[key] / max_var * (2**(BIT_WIDTH-1)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Summary\n",
      "0 input_1 0 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "1 conv2d 2 input (None, 28, 28, 1) output (None, 24, 24, 32)\n",
      "Part 2 Summary\n",
      "0 input_2 0 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "1 max_pooling2d 0 input (None, 24, 24, 32) output (None, 12, 12, 32)\n",
      "2 conv2d_1 2 input (None, 12, 12, 32) output (None, 8, 8, 64)\n",
      "3 max_pooling2d_1 0 input (None, 8, 8, 64) output (None, 4, 4, 64)\n",
      "4 conv2d_2 2 input (None, 4, 4, 64) output (None, 2, 2, 96)\n",
      "5 max_pooling2d_2 0 input (None, 2, 2, 96) output (None, 1, 1, 96)\n",
      "6 flatten 0 input (None, 1, 1, 96) output (None, 96)\n",
      "7 dense_last 2 input (None, 96) output (None, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Summary\")\n",
    "for i, layer in enumerate(nq_model_part1.layers):\n",
    "    print(i, layer.name, len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)\n",
    "print(\"Part 2 Summary\")\n",
    "for i, layer in enumerate(nq_model_part2.layers):\n",
    "    print(i, layer.name, len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Trainable\n",
      "1 conv2d conv2d/kernel:0\n",
      "1 conv2d conv2d/bias:0\n",
      "Part 1 Non Trainable\n",
      "Part 2 Trainable\n",
      "2 conv2d_1 conv2d_1/kernel:0\n",
      "2 conv2d_1 conv2d_1/bias:0\n",
      "4 conv2d_2 conv2d_2/kernel:0\n",
      "4 conv2d_2 conv2d_2/bias:0\n",
      "7 dense_last dense_last/kernel:0\n",
      "7 dense_last dense_last/bias:0\n",
      "Part 2 Non Trainable\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Trainable\")\n",
    "for i, layer in enumerate(nq_model_part1.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)\n",
    "print(\"Part 1 Non Trainable\")\n",
    "for i, layer in enumerate(nq_model_part1.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)\n",
    "print(\"Part 2 Trainable\")\n",
    "for i, layer in enumerate(nq_model_part2.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)\n",
    "print(\"Part 2 Non Trainable\")\n",
    "for i, layer in enumerate(nq_model_part2.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 9]\n",
      "[[-0.07918215 -0.01161032  0.07245282]\n",
      " [ 0.00061669 -0.22089666 -0.01293123]\n",
      " [ 0.03844265  0.06296697  0.14747679]]\n",
      "[[-0.07918215 -0.01161032  0.07245282]\n",
      " [ 0.00061669 -0.22089666 -0.01293123]\n",
      " [ 0.03844265  0.06296697  0.14747679]]\n",
      "[ 0.02969096  0.01373224 -0.25231063 -0.01235129 -0.03170829]\n",
      "[ 0.02969096  0.01373224 -0.25231063 -0.01235129 -0.03170829]\n",
      "[[ 0.00423666 -0.10165723 -0.21178155]\n",
      " [-0.1674046  -0.30126658 -0.01047609]\n",
      " [-0.1538336  -0.02137352 -0.08994394]]\n",
      "[[ 0.00423666 -0.10165723 -0.21178155]\n",
      " [-0.1674046  -0.30126658 -0.01047609]\n",
      " [-0.1538336  -0.02137352 -0.08994394]]\n",
      "[-0.0156321  -0.01641378 -0.03496066 -0.13640228  0.00386511]\n",
      "[-0.0156321  -0.01641378 -0.03496066 -0.13640228  0.00386511]\n"
     ]
    }
   ],
   "source": [
    "print(layer_index_list)\n",
    "indexes_part1 = [1]\n",
    "indexes_part2 = [2, 4, 7]\n",
    "weights_1 = q_aware_model.layers[layer_index_list[0]].get_weights()\n",
    "weights_2 = [q_aware_model.layers[idx].get_weights() for idx in layer_index_list[1:]]\n",
    "# print([variable.name for variable in q_aware_model.layers[layer_index_list[0]].trainable_variables])\n",
    "for idx in indexes_part1:\n",
    "    nq_model_part1.layers[idx].set_weights(weights_1[:2])\n",
    "for i, idx in enumerate(indexes_part2):\n",
    "    nq_model_part2.layers[idx].set_weights(weights_2[i][:2])\n",
    "\n",
    "print(q_aware_model.layers[layer_index_list[0]].trainable_variables[0][:3,:3,0,5].numpy())\n",
    "print(nq_model_part1.layers[1].variables[0][:3,:3,0,5].numpy())\n",
    "print(q_aware_model.layers[layer_index_list[0]].trainable_variables[1][:5].numpy())\n",
    "print(nq_model_part1.layers[1].variables[1][:5].numpy())\n",
    "\n",
    "print(q_aware_model.layers[layer_index_list[2]].trainable_variables[0][:3,:3,0,15].numpy())\n",
    "print(nq_model_part2.layers[4].variables[0][:3,:3,0,15].numpy())\n",
    "print(q_aware_model.layers[layer_index_list[2]].trainable_variables[1][:5].numpy())\n",
    "print(nq_model_part2.layers[4].variables[1][:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape (60000, 28, 28)\n",
      "out images shape (1, 24, 24, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 650x200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02695452 0.02885798 0.00449268 0.02263477]\n",
      " [0.03401939 0.024934   0.00543544 0.        ]\n",
      " [0.04594108 0.         0.0026864  0.        ]\n",
      " [0.02412694 0.         0.         0.        ]]\n",
      "[[0.02695452 0.02885798 0.00449269 0.02263477]\n",
      " [0.0340194  0.024934   0.00543544 0.        ]\n",
      " [0.04594108 0.         0.0026864  0.        ]\n",
      " [0.02412694 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test to replicate the behaviour of first layer\n",
    "TARGET_IMAGE = 1074\n",
    "TARGET_LAYER_FOO = 1\n",
    "T_VARIABLES_KERNEL_INDEX = 0\n",
    "T_VARIABLES_BIAS_INDEX = 1\n",
    "OUT_CHANNEL = 23\n",
    "\n",
    "foo_image = np.zeros((28,28))\n",
    "foo_image[4,4] = 1\n",
    "\n",
    "out = nq_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "# out = nq_model_part1(foo_image[np.newaxis])\n",
    "\n",
    "kernel = nq_model_part1.layers[TARGET_LAYER_FOO].trainable_variables[T_VARIABLES_KERNEL_INDEX][:,:,0,OUT_CHANNEL].numpy()\n",
    "bias = nq_model_part1.layers[TARGET_LAYER_FOO].trainable_variables[T_VARIABLES_BIAS_INDEX][OUT_CHANNEL].numpy()\n",
    "\n",
    "# self_conv = sp.signal.correlate2d(foo_image, kernel, mode = \"valid\") + bias\n",
    "self_conv = sp.signal.correlate2d(train_images[TARGET_IMAGE], kernel, mode = \"valid\") + bias\n",
    "self_conv = np.maximum(0, self_conv)\n",
    "print(\"train images shape\", train_images.shape)\n",
    "print(\"out images shape\", out.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (6.5, 2))\n",
    "ax[0].imshow(train_images[TARGET_IMAGE], cmap = 'Greys')\n",
    "# ax[0].imshow(foo_image, cmap = 'Greys')\n",
    "ax[0].set_title('original input')\n",
    "ax[0].axis('equal')\n",
    "ax[0].set(xlim = (0, train_images.shape[-2:][0]), ylim = (train_images.shape[-2:][1], 0))\n",
    "\n",
    "ax[1].imshow(out[0,:,:,OUT_CHANNEL], cmap = 'Greys')\n",
    "ax[1].set_title('first layer output')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "\n",
    "ax[2].imshow(self_conv, cmap = 'Greys')\n",
    "ax[2].set_title('self convolution')\n",
    "ax[2].axis('equal')\n",
    "ax[2].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "slicer = slice(None,4)\n",
    "print(self_conv[(slicer,slicer)])\n",
    "print(out[(0,slicer,slicer,OUT_CHANNEL)].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] [0.] [0.] [0.] [0.] [0.] [0.] [0.] [0.] [0.]\n"
     ]
    }
   ],
   "source": [
    "# Compare weights and biases\n",
    "# print(\"Original trainable variables\")\n",
    "# for layer in q_aware_model.layers:\n",
    "#     for variable in layer.trainable_variables:\n",
    "#         print(variable.name)\n",
    "# print(\"\\nPart 1 variables\")\n",
    "# for layer in nq_model_part1.layers:\n",
    "#     for variable in layer.variables:\n",
    "#         print(variable.name)\n",
    "# print(\"\\nPart 2 variables\")\n",
    "# for layer in nq_model_part2.layers:\n",
    "#     for variable in layer.variables:\n",
    "#         print(variable.name)\n",
    "KERNEL_INDEX = 0\n",
    "BIAS_INDEX = 1\n",
    "original_layer_vars = [[variable.numpy() for variable in q_aware_model.layers[idx].trainable_variables] for idx in layer_index_list]\n",
    "\n",
    "print(np.unique((nq_model_part1.layers[indexes_part1[0]].variables[KERNEL_INDEX] - original_layer_vars[0][KERNEL_INDEX]).numpy()),\n",
    "np.unique((nq_model_part1.layers[indexes_part1[0]].variables[BIAS_INDEX] - original_layer_vars[0][BIAS_INDEX]).numpy()),\n",
    "\n",
    "np.unique((nq_model_part2.layers[indexes_part2[0]].variables[KERNEL_INDEX] - original_layer_vars[1][KERNEL_INDEX]).numpy()),\n",
    "np.unique((nq_model_part2.layers[indexes_part2[0]].variables[BIAS_INDEX] - original_layer_vars[1][BIAS_INDEX]).numpy()),\n",
    "\n",
    "np.unique((nq_model_part2.layers[indexes_part2[1]].variables[KERNEL_INDEX] - original_layer_vars[2][KERNEL_INDEX]).numpy()),\n",
    "np.unique((nq_model_part2.layers[indexes_part2[1]].variables[BIAS_INDEX] - original_layer_vars[2][BIAS_INDEX]).numpy()),\n",
    "\n",
    "np.unique((nq_model_part2.layers[indexes_part2[1]].variables[KERNEL_INDEX] - original_layer_vars[2][KERNEL_INDEX]).numpy()),\n",
    "np.unique((nq_model_part2.layers[indexes_part2[1]].variables[BIAS_INDEX] - original_layer_vars[2][BIAS_INDEX]).numpy()),\n",
    "\n",
    "np.unique((nq_model_part2.layers[indexes_part2[2]].variables[KERNEL_INDEX] - original_layer_vars[3][KERNEL_INDEX]).numpy()),\n",
    "np.unique((nq_model_part2.layers[indexes_part2[2]].variables[BIAS_INDEX] - original_layer_vars[3][BIAS_INDEX]).numpy()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Part 1 Summary\n",
      "0 input_1 vars 0 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "1 quantize_layer vars 3 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "2 quant_conv2d vars 7 input (None, 28, 28, 1) output (None, 24, 24, 32)\n",
      "Q Part 2 Summary\n",
      "0 input_2 vars 0 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "1 quantize_layer_1 vars 3 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "2 quant_max_pooling2d vars 1 input (None, 24, 24, 32) output (None, 12, 12, 32)\n",
      "3 quant_conv2d_1 vars 7 input (None, 12, 12, 32) output (None, 8, 8, 64)\n",
      "4 quant_max_pooling2d_1 vars 1 input (None, 8, 8, 64) output (None, 4, 4, 64)\n",
      "5 quant_conv2d_2 vars 7 input (None, 4, 4, 64) output (None, 2, 2, 96)\n",
      "6 quant_max_pooling2d_2 vars 1 input (None, 2, 2, 96) output (None, 1, 1, 96)\n",
      "7 quant_flatten vars 1 input (None, 1, 1, 96) output (None, 96)\n",
      "8 quant_dense_last vars 7 input (None, 96) output (None, 10)\n"
     ]
    }
   ],
   "source": [
    "q_model_part1 = tfmot.quantization.keras.quantize_model(nq_model_part1)\n",
    "q_model_part2 = tfmot.quantization.keras.quantize_model(nq_model_part2)\n",
    "print(\"Q Part 1 Summary\")\n",
    "for i, layer in enumerate(q_model_part1.layers):\n",
    "    print(i, layer.name, \"vars\", len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)\n",
    "print(\"Q Part 2 Summary\")\n",
    "for i, layer in enumerate(q_model_part2.layers):\n",
    "    print(i, layer.name, \"vars\", len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Trainable\n",
      "2 quant_conv2d conv2d/kernel:0\n",
      "2 quant_conv2d conv2d/bias:0\n",
      "Part 2 Trainable\n",
      "3 quant_conv2d_1 conv2d_1/kernel:0\n",
      "3 quant_conv2d_1 conv2d_1/bias:0\n",
      "5 quant_conv2d_2 conv2d_2/kernel:0\n",
      "5 quant_conv2d_2 conv2d_2/bias:0\n",
      "8 quant_dense_last dense_last/kernel:0\n",
      "8 quant_dense_last dense_last/bias:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Trainable\")\n",
    "for i, layer in enumerate(q_model_part1.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)\n",
    "print(\"Part 2 Trainable\")\n",
    "for i, layer in enumerate(q_model_part2.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Non Trainable\n",
      "1 quantize_layer quantize_layer/quantize_layer_min:0\n",
      "1 quantize_layer quantize_layer/quantize_layer_max:0\n",
      "1 quantize_layer quantize_layer/optimizer_step:0\n",
      "2 quant_conv2d quant_conv2d/optimizer_step:0\n",
      "2 quant_conv2d quant_conv2d/kernel_min:0\n",
      "2 quant_conv2d quant_conv2d/kernel_max:0\n",
      "2 quant_conv2d quant_conv2d/post_activation_min:0\n",
      "2 quant_conv2d quant_conv2d/post_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Non Trainable\")\n",
    "for i, layer in enumerate(q_model_part1.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 Non Trainable\n",
      "1 quantize_layer_1 quantize_layer_1/quantize_layer_1_min:0\n",
      "1 quantize_layer_1 quantize_layer_1/quantize_layer_1_max:0\n",
      "1 quantize_layer_1 quantize_layer_1/optimizer_step:0\n",
      "2 quant_max_pooling2d quant_max_pooling2d/optimizer_step:0\n",
      "3 quant_conv2d_1 quant_conv2d_1/optimizer_step:0\n",
      "3 quant_conv2d_1 quant_conv2d_1/kernel_min:0\n",
      "3 quant_conv2d_1 quant_conv2d_1/kernel_max:0\n",
      "3 quant_conv2d_1 quant_conv2d_1/post_activation_min:0\n",
      "3 quant_conv2d_1 quant_conv2d_1/post_activation_max:0\n",
      "4 quant_max_pooling2d_1 quant_max_pooling2d_1/optimizer_step:0\n",
      "5 quant_conv2d_2 quant_conv2d_2/optimizer_step:0\n",
      "5 quant_conv2d_2 quant_conv2d_2/kernel_min:0\n",
      "5 quant_conv2d_2 quant_conv2d_2/kernel_max:0\n",
      "5 quant_conv2d_2 quant_conv2d_2/post_activation_min:0\n",
      "5 quant_conv2d_2 quant_conv2d_2/post_activation_max:0\n",
      "6 quant_max_pooling2d_2 quant_max_pooling2d_2/optimizer_step:0\n",
      "7 quant_flatten quant_flatten/optimizer_step:0\n",
      "8 quant_dense_last quant_dense_last/optimizer_step:0\n",
      "8 quant_dense_last quant_dense_last/kernel_min:0\n",
      "8 quant_dense_last quant_dense_last/kernel_max:0\n",
      "8 quant_dense_last quant_dense_last/pre_activation_min:0\n",
      "8 quant_dense_last quant_dense_last/pre_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2 Non Trainable\")\n",
    "for i, layer in enumerate(q_model_part2.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] [0.] [0] [0.] [0.] [0] [0.] [0.] [0.] [0.] [-3.9335735] [4.380244] [-1] [0] [0.] [0.] [0] [0.] [0.] [0.] [0.] [0] [0.] [0.] [0] [0.] [0.] [0.] [0.] [0] [0] [0.] [0.] [0] [0.] [0.] [0.] [0.]\n"
     ]
    }
   ],
   "source": [
    "q_indexes_part1 = [1, 2]\n",
    "q_indexes_part2 = list(range(3, 9 + 1))\n",
    "q_indexes_part2_2 = list(range(2, 8 + 1))\n",
    "# for i, layer in enumerate(q_aware_model.layers):\n",
    "#     # layer.get_weights()\n",
    "#     if len(layer.get_weights()) != 0:\n",
    "#         print(i)\n",
    "q_weights_1 = [q_aware_model.layers[idx].get_weights() for idx in q_indexes_part1]\n",
    "q_weights_2 = [q_aware_model.layers[idx].get_weights() for idx in q_indexes_part2]\n",
    "# print(q_weights_1[0])\n",
    "for i, idx in enumerate(q_indexes_part1):\n",
    "    q_model_part1.layers[idx].set_weights(q_weights_1[i])\n",
    "intermediate_max_min = q_aware_model.layers[2].get_weights()[-2:]\n",
    "intermediate_max_min.append(-1)\n",
    "q_model_part2.layers[1].set_weights(intermediate_max_min)\n",
    "for i, idx in enumerate(q_indexes_part2_2):\n",
    "    q_model_part2.layers[idx].set_weights(q_weights_2[i])\n",
    "\n",
    "KERNEL_INDEX = 0\n",
    "BIAS_INDEX = 1\n",
    "# print(q_model_part1.layers[q_indexes_part1[1]].variables)\n",
    "# print(q_aware_model.layers[q_indexes_part1[1]].variables)\n",
    "print(np.unique((q_model_part1.layers[q_indexes_part1[0]].variables[0] - q_aware_model.layers[q_indexes_part1[0]].variables[0]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[0]].variables[1] - q_aware_model.layers[q_indexes_part1[0]].variables[1]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[0]].variables[2] - q_aware_model.layers[q_indexes_part1[0]].variables[2]).numpy()),\n",
    "\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[0] - q_aware_model.layers[q_indexes_part1[1]].variables[0]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[1] - q_aware_model.layers[q_indexes_part1[1]].variables[1]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[2] - q_aware_model.layers[q_indexes_part1[1]].variables[2]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[3] - q_aware_model.layers[q_indexes_part1[1]].variables[3]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[4] - q_aware_model.layers[q_indexes_part1[1]].variables[4]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[5] - q_aware_model.layers[q_indexes_part1[1]].variables[5]).numpy()),\n",
    "np.unique((q_model_part1.layers[q_indexes_part1[1]].variables[6] - q_aware_model.layers[q_indexes_part1[1]].variables[6]).numpy()),\n",
    "\n",
    "np.unique(q_model_part2.layers[1].variables[0].numpy()),\n",
    "np.unique(q_model_part2.layers[1].variables[1].numpy()),\n",
    "np.unique(q_model_part2.layers[1].variables[2].numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[0]].variables[0] - q_aware_model.layers[q_indexes_part2[0]].variables[0]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[0] - q_aware_model.layers[q_indexes_part2[1]].variables[0]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[1] - q_aware_model.layers[q_indexes_part2[1]].variables[1]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[2] - q_aware_model.layers[q_indexes_part2[1]].variables[2]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[3] - q_aware_model.layers[q_indexes_part2[1]].variables[3]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[4] - q_aware_model.layers[q_indexes_part2[1]].variables[4]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[5] - q_aware_model.layers[q_indexes_part2[1]].variables[5]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[1]].variables[6] - q_aware_model.layers[q_indexes_part2[1]].variables[6]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[2]].variables[0] - q_aware_model.layers[q_indexes_part2[2]].variables[0]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[0] - q_aware_model.layers[q_indexes_part2[3]].variables[0]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[1] - q_aware_model.layers[q_indexes_part2[3]].variables[1]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[2] - q_aware_model.layers[q_indexes_part2[3]].variables[2]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[3] - q_aware_model.layers[q_indexes_part2[3]].variables[3]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[4] - q_aware_model.layers[q_indexes_part2[3]].variables[4]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[5] - q_aware_model.layers[q_indexes_part2[3]].variables[5]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[3]].variables[6] - q_aware_model.layers[q_indexes_part2[3]].variables[6]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[4]].variables[0] - q_aware_model.layers[q_indexes_part2[4]].variables[0]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[5]].variables[0] - q_aware_model.layers[q_indexes_part2[5]].variables[0]).numpy()),\n",
    "\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[0] - q_aware_model.layers[q_indexes_part2[6]].variables[0]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[1] - q_aware_model.layers[q_indexes_part2[6]].variables[1]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[2] - q_aware_model.layers[q_indexes_part2[6]].variables[2]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[3] - q_aware_model.layers[q_indexes_part2[6]].variables[3]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[4] - q_aware_model.layers[q_indexes_part2[6]].variables[4]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[5] - q_aware_model.layers[q_indexes_part2[6]].variables[5]).numpy()),\n",
    "np.unique((q_model_part2.layers[q_indexes_part2_2[6]].variables[6] - q_aware_model.layers[q_indexes_part2[6]].variables[6]).numpy()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original output\n",
      " [[1.8473416e-09 9.9999988e-01 2.5903853e-08 4.0264447e-10 5.8375569e-08\n",
      "  5.6541989e-12 1.2723472e-08 5.6541989e-12 2.6821853e-10 5.6541989e-12]]\n",
      "non quantized model output\n",
      " [[1.4625762e-15 1.0000000e+00 7.5149568e-15 4.2900803e-17 9.2893006e-14\n",
      "  1.2390763e-24 2.8898564e-15 5.6050442e-23 1.1157035e-16 4.4603877e-22]]\n",
      "quantized model output\n",
      " [[1.8473416e-09 9.9999988e-01 2.5903853e-08 4.0264447e-10 5.8375569e-08\n",
      "  5.6541989e-12 1.2723472e-08 5.6541989e-12 2.6821853e-10 5.6541989e-12]]\n",
      "\n",
      "Unique difference non quantized [-1.1920929e-07  5.6541989e-12  2.6821842e-10  4.0264442e-10\n",
      "  1.8473402e-09  1.2723469e-08  2.5903846e-08  5.8375477e-08]\n",
      "Unique difference quantized [0.]\n"
     ]
    }
   ],
   "source": [
    "# Test compare inference both original and parts-model\n",
    "TARGET_IMAGE = 2100\n",
    "out_original = q_aware_model(train_images[np.newaxis,TARGET_IMAGE])\n",
    "\n",
    "# Does not yield the same results\n",
    "out_1 = nq_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out_2 = nq_model_part2(out_1)\n",
    "\n",
    "# Yields the same results\n",
    "out_3 = q_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out_4 = q_model_part2(out_3)\n",
    "\n",
    "print(\"original output\\n\", out_original .numpy())\n",
    "print(\"non quantized model output\\n\", out_2.numpy())\n",
    "print(\"quantized model output\\n\", out_4.numpy())\n",
    "print(\"\\nUnique difference non quantized\", np.unique((out_original - out_2).numpy()))\n",
    "print(\"Unique difference quantized\", np.unique((out_original - out_4).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.05969456 0.18146738 0.3515631  0.        ]\n",
      " [0.09428683 0.22077817 0.32558832 0.        ]\n",
      " [0.10542884 0.23796675 0.30107716 0.        ]\n",
      " [0.10430839 0.2293778  0.27900246 0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.06520641 0.19561923 0.35863525 0.        ]\n",
      " [0.09780961 0.22822243 0.32603204 0.        ]\n",
      " [0.09780961 0.22822243 0.29342884 0.        ]\n",
      " [0.09780961 0.22822243 0.29342884 0.        ]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "OUT_CHANNEL = 1\n",
    "fig, ax = plt.subplots(1, 2, figsize = (4.5, 2))\n",
    "\n",
    "ax[0].imshow(out_1[0,:,:,OUT_CHANNEL], cmap = 'Greys')\n",
    "ax[0].set_title('Non quantized model')\n",
    "ax[0].axis('equal')\n",
    "ax[0].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "\n",
    "ax[1].imshow(out_3[0,:,:,OUT_CHANNEL], cmap = 'Greys')\n",
    "ax[1].set_title('Quantized model')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "slicer = slice(5, 9)\n",
    "print(out_1[0, slicer, slicer, OUT_CHANNEL])\n",
    "print(out_3[0, slicer, slicer, OUT_CHANNEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantize_layer\n",
      "quant_conv2d\n",
      "input scale 0.00392156862745098\n",
      "input zero -128\n",
      "kernel scales [0.00329171 0.00318886 0.00154461 0.00221212 0.00216033 0.00173925\n",
      " 0.00257462 0.00135561 0.00259043 0.00228444 0.01463084 0.00207081\n",
      " 0.00626407 0.00238244 0.01474832 0.00248384 0.00260051 0.00279522\n",
      " 0.00929473 0.002684   0.00207167 0.0020169  0.00217691 0.00185296\n",
      " 0.00304491 0.00207702 0.0010245  0.00203166 0.00265791 0.00135298\n",
      " 0.00273699 0.00247921]\n",
      "bias scales [1.2908661e-05 1.2505331e-05 6.0573111e-06 8.6749860e-06 8.4718740e-06\n",
      " 6.8206023e-06 1.0096539e-05 5.3161089e-06 1.0158549e-05 8.9585819e-06\n",
      " 5.7375863e-05 8.1208136e-06 2.4564994e-05 9.3428880e-06 5.7836533e-05\n",
      " 9.7405646e-06 1.0198080e-05 1.0961662e-05 3.6449925e-05 1.0525496e-05\n",
      " 8.1241951e-06 7.9094089e-06 8.5368883e-06 7.2664952e-06 1.1940828e-05\n",
      " 8.1451790e-06 4.0176528e-06 7.9673073e-06 1.0423187e-05 5.3058229e-06\n",
      " 1.0733294e-05 9.7224120e-06]\n",
      "activation scale 0.03260320401659199\n",
      "activation zero -7\n",
      "bias [  2300   1098 -41654  -1424  -3743 -19204  -1805   3815  -1373  -1241\n",
      "   4801   -235   4490  -1226   5328  -3315    819   1959   4093   -688\n",
      "  -2146   1330  -3142   3709  -2705  18189 -55454  -1871     36 -43575\n",
      "   1414   -575]\n",
      "bias ['0x8fc', '0x44a', '0xffff5d4a', '0xfffffa70', '0xfffff161', '0xffffb4fc', '0xfffff8f3', '0xee7', '0xfffffaa3', '0xfffffb27', '0x12c1', '0xffffff15', '0x118a', '0xfffffb36', '0x14d0', '0xfffff30d', '0x333', '0x7a7', '0xffd', '0xfffffd50', '0xfffff79e', '0x532', '0xfffff3ba', '0xe7d', '0xfffff56f', '0x470d', '0xffff2762', '0xfffff8b1', '0x24', '0xffff55c9', '0x586', '0xfffffdc1']\n"
     ]
    }
   ],
   "source": [
    "INPUT_LAYER = 1\n",
    "CONV1_LAYER = 2\n",
    "BIT_WIDTH = 8\n",
    "BIAS_BIT_WIDTH = 32\n",
    "T_VARIABLES_KERNEL_INDEX = 0\n",
    "T_VARIABLES_BIAS_INDEX = 1\n",
    "\n",
    "print(q_aware_model.layers[INPUT_LAYER].name)\n",
    "vars_input = {variable.name: variable.numpy() for i, variable in enumerate(q_aware_model.layers[INPUT_LAYER].non_trainable_variables) if \"min\" in variable.name or \"max\" in variable.name}\n",
    "# print(vars_input)\n",
    "quantize_keys_input = [key for key in vars_input if \"quantize\" in key]\n",
    "kernel_keys_input = [key for key in vars_input if \"kernel\" in key]\n",
    "activation_keys_input = [key for key in vars_input if \"activation\" in key]\n",
    "if len(quantize_keys_input) != 0:\n",
    "    min_quantize_key_input, = tuple(key for key in quantize_keys_input if \"min\" in key)\n",
    "    max_quantize_key_input, = tuple(key for key in quantize_keys_input if \"max\" in key)\n",
    "else:\n",
    "    min_quantize_key_input = None\n",
    "    max_quantize_key_input = None\n",
    "if len(kernel_keys_input) != 0:\n",
    "    min_kernel_key_input, = tuple(key for key in kernel_keys_input if \"min\" in key)\n",
    "    max_kernel_key_input, = tuple(key for key in kernel_keys_input if \"max\" in key)\n",
    "else:\n",
    "    min_kernel_key_input = None\n",
    "    max_kernel_key_input = None\n",
    "if len(activation_keys_input) != 0:\n",
    "    min_activ_key_input, = tuple(key for key in activation_keys_input if \"min\" in key)\n",
    "    max_activ_key_input, = tuple(key for key in activation_keys_input if \"max\" in key)\n",
    "else:\n",
    "    min_activ_key_input = None\n",
    "    max_activ_key_input = None\n",
    "\n",
    "print(q_aware_model.layers[CONV1_LAYER].name)\n",
    "vars_conv1 = {variable.name: variable.numpy() for i, variable in enumerate(q_aware_model.layers[CONV1_LAYER].non_trainable_variables) if \"min\" in variable.name or \"max\" in variable.name}\n",
    "# print(vars_conv1)\n",
    "quantize_keys_conv1 = [key for key in vars_conv1 if \"quantize\" in key]\n",
    "kernel_keys_conv1 = [key for key in vars_conv1 if \"kernel\" in key]\n",
    "activation_keys_conv1 = [key for key in vars_conv1 if \"activation\" in key]\n",
    "if len(quantize_keys_conv1) != 0:\n",
    "    min_quantize_key_conv1, = tuple(key for key in quantize_keys_conv1 if \"min\" in key)\n",
    "    max_quantize_key_conv1, = tuple(key for key in quantize_keys_conv1 if \"max\" in key)\n",
    "else:\n",
    "    min_quantize_key_conv1 = None\n",
    "    max_quantize_key_conv1 = None\n",
    "if len(kernel_keys_conv1) != 0:\n",
    "    min_kernel_key_conv1, = tuple(key for key in kernel_keys_conv1 if \"min\" in key)\n",
    "    max_kernel_key_conv1, = tuple(key for key in kernel_keys_conv1 if \"max\" in key)\n",
    "else:\n",
    "    min_kernel_key_conv1 = None\n",
    "    max_kernel_key_conv1 = None\n",
    "if len(activation_keys_conv1) != 0:\n",
    "    min_activ_key_conv1, = tuple(key for key in activation_keys_conv1 if \"min\" in key)\n",
    "    max_activ_key_conv1, = tuple(key for key in activation_keys_conv1 if \"max\" in key)\n",
    "else:\n",
    "    min_activ_key_conv1 = None\n",
    "    max_activ_key_conv1 = None\n",
    "\n",
    "input_min = vars_input.get(min_quantize_key_input)\n",
    "input_max = vars_input.get(max_quantize_key_input)\n",
    "kernel_min = vars_conv1.get(min_kernel_key_conv1)\n",
    "kernel_max = vars_conv1.get(max_kernel_key_conv1)\n",
    "activation_min = vars_conv1.get(min_activ_key_conv1)\n",
    "activation_max = vars_conv1.get(max_activ_key_conv1)\n",
    "\n",
    "# Input scales and zeros\n",
    "input_scale = (input_max - input_min) / (2**BIT_WIDTH - 1)\n",
    "input_zero = np.round(2**(BIT_WIDTH - 1) - 1 - input_max/input_scale).astype(int)\n",
    "# Kernel and biases scales\n",
    "# kernel_scales = (kernel_max - kernel_min) / (2**BIT_WIDTH - 2)\n",
    "kernel_scales = kernel_max / (2**(BIT_WIDTH - 1) - 1)\n",
    "bias_scales = input_scale * kernel_scales\n",
    "# Output scale and zero\n",
    "activation_scale = (activation_max - activation_min) / (2**BIT_WIDTH - 1)\n",
    "activation_zero = np.round(2**(BIT_WIDTH - 1) - 1 - activation_max/activation_scale).astype(int)\n",
    "\n",
    "print(\"input scale\", input_scale)\n",
    "print(\"input zero\", input_zero)\n",
    "print(\"kernel scales\", kernel_scales)\n",
    "print(\"bias scales\", bias_scales)\n",
    "print(\"activation scale\", activation_scale)\n",
    "print(\"activation zero\", activation_zero)\n",
    "\n",
    "bias_ints = np.round(q_aware_model.layers[CONV1_LAYER].trainable_variables[T_VARIABLES_BIAS_INDEX].numpy() / bias_scales).astype(int)\n",
    "print(\"bias\", bias_ints)\n",
    "print(\"bias\", [hex(bias) if bias > 0 else hex((-bias ^ 0xFFFFFFFF) + 1) for bias in bias_ints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-128   33   19   32   42]\n",
      " [-126   47   18   17   40]\n",
      " [ -93   49   27   12   23]\n",
      " [ -69   42   25   13   -8]\n",
      " [ -49   17   32   86   -5]]\n",
      "[[0.         0.63137255 0.57647059 0.62745098 0.66666667]\n",
      " [0.00784314 0.68627451 0.57254902 0.56862745 0.65882353]\n",
      " [0.1372549  0.69411765 0.60784314 0.54901961 0.59215686]\n",
      " [0.23137255 0.66666667 0.6        0.55294118 0.47058824]\n",
      " [0.30980392 0.56862745 0.62745098 0.83921569 0.48235294]]\n",
      "[[0.         0.63137255 0.57647059 0.62745098 0.66666667]\n",
      " [0.00784314 0.68627451 0.57254902 0.56862745 0.65882353]\n",
      " [0.1372549  0.69411765 0.60784314 0.54901961 0.59215686]\n",
      " [0.23137255 0.66666667 0.6        0.55294118 0.47058824]\n",
      " [0.30980392 0.56862745 0.62745098 0.83921569 0.48235294]]\n",
      "Unique [0.00000000e+00 2.77555756e-17 5.55111512e-17 1.11022302e-16]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test compare inference both original and parts-model\n",
    "TARGET_IMAGE = 10\n",
    "TARGET_LAYER_FOO = 1\n",
    "T_VARIABLES_KERNEL_INDEX = 0\n",
    "T_VARIABLES_BIAS_INDEX = 1\n",
    "OUT_CHANNEL = 29\n",
    "slicer = slice(4,9)\n",
    "quantized_input_image = np.round(train_images[np.newaxis,TARGET_IMAGE]/input_scale).astype(int) + input_zero\n",
    "quantized_and_dequantized_input = input_scale*(quantized_input_image - input_zero)\n",
    "\n",
    "print(quantized_input_image[0,slicer,slicer])\n",
    "print(train_images[TARGET_IMAGE, slicer, slicer])\n",
    "print(quantized_and_dequantized_input[0,slicer,slicer])\n",
    "print(\"Unique\", np.unique(train_images[TARGET_IMAGE] - quantized_and_dequantized_input[0,:,:]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (4.5, 2))\n",
    "\n",
    "ax[0].imshow(train_images[TARGET_IMAGE], cmap = 'Greys')\n",
    "ax[0].set_title('Non quantized model')\n",
    "ax[0].axis('equal')\n",
    "ax[0].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "\n",
    "ax[1].imshow(quantized_and_dequantized_input[0,:,:], cmap = 'Greys')\n",
    "ax[1].set_title('Quantized dequantized model')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(1, 28, 28)\n",
      "(1, 24, 24, 32)\n",
      "-43575\n",
      "[[0.         0.         0.         0.0326032  0.0326032 ]\n",
      " [0.         0.         0.         0.         0.0326032 ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.16301602 0.16301602 0.06520641 0.         0.        ]\n",
      " [0.26082563 0.29342884 0.19561923 0.13041282 0.        ]]\n",
      "[[0.         0.         0.         0.01980133 0.03946471]\n",
      " [0.         0.         0.         0.         0.01970583]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.15172531 0.17578722 0.07327872 0.00453648 0.        ]\n",
      " [0.24928348 0.3046126  0.20572267 0.12452766 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_original = q_aware_model(train_images[np.newaxis,TARGET_IMAGE])\n",
    "\n",
    "# Two part model output\n",
    "out_3 = q_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out_4 = q_model_part2(out_3)\n",
    "\n",
    "# First layer\n",
    "key = keys_list[0]\n",
    "\n",
    "kernel = quantized[key][:,:,0,OUT_CHANNEL]\n",
    "bias = bias_ints[OUT_CHANNEL]\n",
    "print(kernel.shape)\n",
    "print(quantized_input_image.shape)\n",
    "print(out_3.shape)\n",
    "\n",
    "print(bias)\n",
    "\n",
    "# self_conv = sp.signal.correlate2d(foo_image, kernel, mode = \"valid\") + bias\n",
    "self_conv = sp.signal.correlate2d(quantized_input_image[0] - input_zero, kernel, mode = \"valid\").astype(int) + bias\n",
    "self_conv = np.maximum(0, self_conv)\n",
    "\n",
    "self_conv_float = bias_scales[OUT_CHANNEL]*self_conv\n",
    "print(out_3[0,slicer,slicer,OUT_CHANNEL].numpy())\n",
    "print(self_conv_float[slicer,slicer])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (4.5, 2))\n",
    "\n",
    "ax[0].imshow(out_3[0,:,:,OUT_CHANNEL], cmap = 'Greys')\n",
    "ax[0].set_title('Non quantized model')\n",
    "ax[0].axis('equal')\n",
    "ax[0].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "\n",
    "ax[1].imshow(self_conv_float[:,:], cmap = 'Greys')\n",
    "ax[1].set_title('Quantized model')\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlim = (0, out.shape[1:3][0]), ylim = (out.shape[1:3][1], 0))\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "1875/1875 [==============================] - 8s 4ms/step\n",
      "(60000, 10)\n",
      "0.9616833333333333 0.11276093\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1128 - accuracy: 0.9617\n",
      "Q Aware model test accuracy :  96.17%\n",
      "Q Aware model test loss:  0.1127830371260643\n"
     ]
    }
   ],
   "source": [
    "out_train_pt1 = q_model_part1.predict(train_images)\n",
    "out_train_pt2 = q_model_part2.predict(out_train_pt1)\n",
    "print(out_train_pt2.shape)\n",
    "prediction_digits = []\n",
    "for i, image in enumerate(train_images):\n",
    "    prediction_digits.append(np.argmax(out_train_pt2[i]))\n",
    "prediction_digits = np.array(prediction_digits)\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()(train_labels, out_train_pt2)\n",
    "\n",
    "loss = scce.numpy()\n",
    "accuracy = (prediction_digits == train_labels).mean()\n",
    "print(accuracy, loss)\n",
    "\n",
    "q_aware_train_loss, q_aware_train_acc = q_aware_model.evaluate(train_images, train_labels)\n",
    "print('Q Aware model test accuracy : ', \"{:0.2%}\".format(q_aware_train_acc))\n",
    "print('Q Aware model test loss: ', q_aware_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "(10000, 10)\n",
      "0.9115 0.28909135\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2891 - accuracy: 0.9115\n",
      "Q Aware model test accuracy :  91.15%\n",
      "Q Aware model test loss:  0.2890910804271698\n"
     ]
    }
   ],
   "source": [
    "out_test_pt1 = q_model_part1.predict(test_images)\n",
    "out_test_pt2 = q_model_part2.predict(out_test_pt1)\n",
    "print(out_test_pt2.shape)\n",
    "prediction_digits = []\n",
    "for i, image in enumerate(test_images):\n",
    "    prediction_digits.append(np.argmax(out_test_pt2[i]))\n",
    "prediction_digits = np.array(prediction_digits)\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()(test_labels, out_test_pt2)\n",
    "\n",
    "loss = scce.numpy()\n",
    "accuracy = (prediction_digits == test_labels).mean()\n",
    "print(accuracy, loss)\n",
    "\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Q Aware model test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))\n",
    "print('Q Aware model test loss: ', q_aware_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model\n",
      "[[0.         0.         0.13041282 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.0326032  0.         0.        ]\n",
      " [0.         0.22822243 0.         0.        ]]\n",
      "(24, 24, 32)\n",
      "Self quantized model no activation\n",
      "[[0.         0.         0.14309532 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.03776719 0.         0.        ]\n",
      " [0.         0.21986756 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Two part model output\n",
    "TARGET_IMAGE = 5300 #100\n",
    "OUT_CHANNEL = 22 #20\n",
    "\n",
    "(train_images_2, train_labels_2), (test_images_2, test_labels_2) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "quantized_input_image = np.round(train_images[TARGET_IMAGE]/input_scale).astype(int) + input_zero\n",
    "quantized_and_dequantized_input = input_scale*(quantized_input_image - input_zero)\n",
    "\n",
    "out_nq = nq_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out_q = q_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "\n",
    "increment = 4\n",
    "initial_x = 5\n",
    "initial_y = 3\n",
    "sub_pos_x = (initial_x, initial_x + increment)\n",
    "sub_pos_y = (initial_y, initial_y + increment)\n",
    "position = (0, slice(*sub_pos_y), slice(*sub_pos_x), OUT_CHANNEL)\n",
    "# print(\"Original input\")\n",
    "# print(train_images[TARGET_IMAGE, slice(*sub_pos_y), slice(*sub_pos_x)])\n",
    "# print(\"Quantized input\")\n",
    "# print(quantized_and_dequantized_input[slice(*sub_pos_y), slice(*sub_pos_x)])\n",
    "print(\"Quantized model\")\n",
    "print(out_q[position].numpy())\n",
    "\n",
    "# First layer\n",
    "key = keys_list[0]\n",
    "kernel = quantized[key][:,:,0]\n",
    "bias = bias_ints\n",
    "# print(kernel.shape)\n",
    "# print(bias.shape)\n",
    "\n",
    "conv_array = []\n",
    "for channel in range(kernel.shape[-1]):\n",
    "    self_conv = sp.signal.correlate2d(quantized_input_image - input_zero, kernel[:,:,channel], mode = \"valid\").astype(int) + bias[channel]\n",
    "    self_conv = np.maximum(0, self_conv)\n",
    "    float_conv = bias_scales[channel]*self_conv\n",
    "    conv_array.append(float_conv)\n",
    "out_conv = np.array(conv_array)\n",
    "out_conv = np.moveaxis(out_conv, 0, 2)\n",
    "print(out_conv.shape)\n",
    "\n",
    "print(\"Self quantized model no activation\")\n",
    "print(out_conv[position[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between original input no normalization and quantized input\n",
      "[0]\n",
      "Self quantized with activation\n",
      "[[0.         0.         0.13041282 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.0326032  0.         0.        ]\n",
      " [0.         0.22822243 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Difference between original input no normalization and quantized input\")\n",
    "print(np.unique(train_images_2[TARGET_IMAGE] - (quantized_input_image - input_zero)))\n",
    "\n",
    "out_conv_3 = out_conv\n",
    "out_conv_3 = activation_scale * np.round(out_conv_3 / activation_scale)\n",
    "print(\"Self quantized with activation\")\n",
    "print(out_conv_3[position[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "conv_1_1 = tf.keras.layers.Conv2D(32, 5, use_bias = False, activation = None)(input_layer)\n",
    "\n",
    "input_layer_2 = tf.keras.layers.Input(shape = (24, 24, 32))\n",
    "conv_1_2 = tf.keras.layers.Conv2D(32, 1, use_bias = True, activation = 'relu')(input_layer_2)\n",
    "pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1_2)\n",
    "conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu')(pool_1)\n",
    "pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu')(pool_2)\n",
    "pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\")(flat_1)\n",
    "\n",
    "nq2_model_part1 = tf.keras.models.Model(inputs = input_layer, outputs = conv_1_1)\n",
    "nq2_model_part2 = tf.keras.models.Model(inputs = input_layer_2, outputs = dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Summary\n",
      "0 input_5 0 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "1 conv2d_7 1 input (None, 28, 28, 1) output (None, 24, 24, 32)\n",
      "Part 2 Summary\n",
      "0 input_6 0 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "1 conv2d_8 2 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "2 max_pooling2d_6 0 input (None, 24, 24, 32) output (None, 12, 12, 32)\n",
      "3 conv2d_9 2 input (None, 12, 12, 32) output (None, 8, 8, 64)\n",
      "4 max_pooling2d_7 0 input (None, 8, 8, 64) output (None, 4, 4, 64)\n",
      "5 conv2d_10 2 input (None, 4, 4, 64) output (None, 2, 2, 96)\n",
      "6 max_pooling2d_8 0 input (None, 2, 2, 96) output (None, 1, 1, 96)\n",
      "7 flatten_2 0 input (None, 1, 1, 96) output (None, 96)\n",
      "8 dense_last 2 input (None, 96) output (None, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Summary\")\n",
    "for i, layer in enumerate(nq2_model_part1.layers):\n",
    "    print(i, layer.name, len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)\n",
    "print(\"Part 2 Summary\")\n",
    "for i, layer in enumerate(nq2_model_part2.layers):\n",
    "    print(i, layer.name, len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Part 1 Summary\n",
      "0 input_5 vars 0 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "1 quantize_layer_4 vars 3 input (None, 28, 28, 1) output (None, 28, 28, 1)\n",
      "2 quant_conv2d_7 vars 6 input (None, 28, 28, 1) output (None, 24, 24, 32)\n",
      "Q Part 2 Summary\n",
      "0 input_6 vars 0 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "1 quantize_layer_5 vars 3 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "2 quant_conv2d_8 vars 7 input (None, 24, 24, 32) output (None, 24, 24, 32)\n",
      "3 quant_max_pooling2d_6 vars 1 input (None, 24, 24, 32) output (None, 12, 12, 32)\n",
      "4 quant_conv2d_9 vars 7 input (None, 12, 12, 32) output (None, 8, 8, 64)\n",
      "5 quant_max_pooling2d_7 vars 1 input (None, 8, 8, 64) output (None, 4, 4, 64)\n",
      "6 quant_conv2d_10 vars 7 input (None, 4, 4, 64) output (None, 2, 2, 96)\n",
      "7 quant_max_pooling2d_8 vars 1 input (None, 2, 2, 96) output (None, 1, 1, 96)\n",
      "8 quant_flatten_2 vars 1 input (None, 1, 1, 96) output (None, 96)\n",
      "9 quant_dense_last vars 7 input (None, 96) output (None, 10)\n"
     ]
    }
   ],
   "source": [
    "q2_model_part1 = tfmot.quantization.keras.quantize_model(nq2_model_part1)\n",
    "q2_model_part2 = tfmot.quantization.keras.quantize_model(nq2_model_part2)\n",
    "print(\"Q Part 1 Summary\")\n",
    "for i, layer in enumerate(q2_model_part1.layers):\n",
    "    print(i, layer.name, \"vars\", len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)\n",
    "print(\"Q Part 2 Summary\")\n",
    "for i, layer in enumerate(q2_model_part2.layers):\n",
    "    print(i, layer.name, \"vars\", len(layer.variables),\"input\", layer.input.shape, \"output\", layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Trainable\n",
      "2 quant_conv2d_7 conv2d_7/kernel:0\n",
      "Part 2 Trainable\n",
      "2 quant_conv2d_8 conv2d_8/kernel:0\n",
      "2 quant_conv2d_8 conv2d_8/bias:0\n",
      "4 quant_conv2d_9 conv2d_9/kernel:0\n",
      "4 quant_conv2d_9 conv2d_9/bias:0\n",
      "6 quant_conv2d_10 conv2d_10/kernel:0\n",
      "6 quant_conv2d_10 conv2d_10/bias:0\n",
      "9 quant_dense_last dense_last/kernel:0\n",
      "9 quant_dense_last dense_last/bias:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Trainable\")\n",
    "for i, layer in enumerate(q2_model_part1.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)\n",
    "print(\"Part 2 Trainable\")\n",
    "for i, layer in enumerate(q2_model_part2.layers):\n",
    "    for variable in layer.trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Non Trainable\n",
      "1 quantize_layer_4 quantize_layer_4/quantize_layer_4_min:0\n",
      "1 quantize_layer_4 quantize_layer_4/quantize_layer_4_max:0\n",
      "1 quantize_layer_4 quantize_layer_4/optimizer_step:0\n",
      "2 quant_conv2d_7 quant_conv2d_7/optimizer_step:0\n",
      "2 quant_conv2d_7 quant_conv2d_7/kernel_min:0\n",
      "2 quant_conv2d_7 quant_conv2d_7/kernel_max:0\n",
      "2 quant_conv2d_7 quant_conv2d_7/post_activation_min:0\n",
      "2 quant_conv2d_7 quant_conv2d_7/post_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Non Trainable\")\n",
    "for i, layer in enumerate(q2_model_part1.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 Non Trainable\n",
      "1 quantize_layer_5 quantize_layer_5/quantize_layer_5_min:0\n",
      "1 quantize_layer_5 quantize_layer_5/quantize_layer_5_max:0\n",
      "1 quantize_layer_5 quantize_layer_5/optimizer_step:0\n",
      "2 quant_conv2d_8 quant_conv2d_8/optimizer_step:0\n",
      "2 quant_conv2d_8 quant_conv2d_8/kernel_min:0\n",
      "2 quant_conv2d_8 quant_conv2d_8/kernel_max:0\n",
      "2 quant_conv2d_8 quant_conv2d_8/post_activation_min:0\n",
      "2 quant_conv2d_8 quant_conv2d_8/post_activation_max:0\n",
      "3 quant_max_pooling2d_6 quant_max_pooling2d_6/optimizer_step:0\n",
      "4 quant_conv2d_9 quant_conv2d_9/optimizer_step:0\n",
      "4 quant_conv2d_9 quant_conv2d_9/kernel_min:0\n",
      "4 quant_conv2d_9 quant_conv2d_9/kernel_max:0\n",
      "4 quant_conv2d_9 quant_conv2d_9/post_activation_min:0\n",
      "4 quant_conv2d_9 quant_conv2d_9/post_activation_max:0\n",
      "5 quant_max_pooling2d_7 quant_max_pooling2d_7/optimizer_step:0\n",
      "6 quant_conv2d_10 quant_conv2d_10/optimizer_step:0\n",
      "6 quant_conv2d_10 quant_conv2d_10/kernel_min:0\n",
      "6 quant_conv2d_10 quant_conv2d_10/kernel_max:0\n",
      "6 quant_conv2d_10 quant_conv2d_10/post_activation_min:0\n",
      "6 quant_conv2d_10 quant_conv2d_10/post_activation_max:0\n",
      "7 quant_max_pooling2d_8 quant_max_pooling2d_8/optimizer_step:0\n",
      "8 quant_flatten_2 quant_flatten_2/optimizer_step:0\n",
      "9 quant_dense_last quant_dense_last/optimizer_step:0\n",
      "9 quant_dense_last quant_dense_last/kernel_min:0\n",
      "9 quant_dense_last quant_dense_last/kernel_max:0\n",
      "9 quant_dense_last quant_dense_last/pre_activation_min:0\n",
      "9 quant_dense_last quant_dense_last/pre_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2 Non Trainable\")\n",
    "for i, layer in enumerate(q2_model_part2.layers):\n",
    "    for variable in layer.non_trainable_variables:\n",
    "        print(i, layer.name, variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_7/kernel:0\n",
      "quant_conv2d_7/optimizer_step:0\n",
      "quant_conv2d_7/kernel_min:0\n",
      "quant_conv2d_7/kernel_max:0\n",
      "quant_conv2d_7/post_activation_min:0\n",
      "quant_conv2d_7/post_activation_max:0\n"
     ]
    }
   ],
   "source": [
    "TARGET_LAYER = 2\n",
    "for variable in q2_model_part1.layers[TARGET_LAYER].variables:\n",
    "    print(variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non quantized model with quantized weights\n",
      "[[-49752. -20120.  19904. -14789.]\n",
      " [-42347.  -4689. -11192. -49368.]\n",
      " [-25282.   7566. -32724. -76665.]\n",
      " [-13269.  28897. -38694. -79868.]]\n",
      "Self quantized\n",
      "[[-49752 -20120  19904 -14789]\n",
      " [-42347  -4689 -11192 -49368]\n",
      " [-25282   7566 -32724 -76665]\n",
      " [-13269  28897 -38694 -79868]]\n"
     ]
    }
   ],
   "source": [
    "# Two part model output\n",
    "TARGET_IMAGE = 300 #100\n",
    "OUT_CHANNEL = 22 #20\n",
    "\n",
    "q_idx_original_part1 = [1, 2]\n",
    "q_idx_original_part2 = list(range(3, 9 + 1))\n",
    "q_idx_new_part2 = list(range(3, 9 + 1))\n",
    "# for i, layer in enumerate(q_aware_model.layers):\n",
    "#     # layer.get_weights()\n",
    "#     if len(layer.get_weights()) != 0:\n",
    "#         print(i)\n",
    "q_weights_1 = [q_aware_model.layers[idx].get_weights() for idx in q_idx_original_part1]\n",
    "q_weights_2 = [q_aware_model.layers[idx].get_weights() for idx in q_idx_original_part2]\n",
    "q_weights_1_1 = q_weights_1[1].pop(1)\n",
    "# print(q_weights_1[1][1])\n",
    "# print(q_weights_1_1)\n",
    "\n",
    "key = keys_list[0]\n",
    "kernel = quantized[key][:,:,0]\n",
    "bias = bias_ints\n",
    "nq2_model_part1.layers[1].set_weights([quantized[key]])\n",
    "# print(nq2_model_part1.layers[1].variables[0])\n",
    "\n",
    "semi_quantized_input_image = np.round(train_images[TARGET_IMAGE]/input_scale).astype(int)\n",
    "quantized_input_image = np.round(train_images[TARGET_IMAGE]/input_scale).astype(int) + input_zero\n",
    "quantized_and_dequantized_input = input_scale*(quantized_input_image - input_zero)\n",
    "\n",
    "out_nq = nq2_model_part1(semi_quantized_input_image[np.newaxis,:])\n",
    "\n",
    "self_conv = sp.signal.correlate2d(quantized_input_image - input_zero, kernel[:,:,OUT_CHANNEL], mode = \"valid\").astype(int)\n",
    "\n",
    "# out_q = q_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "\n",
    "increment = 4\n",
    "initial_x = 5\n",
    "initial_y = 3\n",
    "sub_pos_x = (initial_x, initial_x + increment)\n",
    "sub_pos_y = (initial_y, initial_y + increment)\n",
    "position = (0, slice(*sub_pos_y), slice(*sub_pos_x), OUT_CHANNEL)\n",
    "print(\"Non quantized model with quantized weights\")\n",
    "print(out_nq[position].numpy())\n",
    "print(\"Self quantized\")\n",
    "print(self_conv[slice(*sub_pos_y), slice(*sub_pos_x)])\n",
    "\n",
    "for i, idx in enumerate(q_idx_original_part1):\n",
    "    q2_model_part1.layers[idx].set_weights(q_weights_1[i])\n",
    "\n",
    "intermediate_max_min = q_aware_model.layers[2].get_weights()[-2:]\n",
    "intermediate_max_min.append(-1)\n",
    "q2_model_part2.layers[1].set_weights(intermediate_max_min)\n",
    "\n",
    "q_weights_1 = [q_aware_model.layers[idx].get_weights() for idx in q_idx_original_part1]\n",
    "q_weights_1[1][0] = np.ones((1,1,32,32))\n",
    "q2_model_part2.layers[2].set_weights(q_weights_1[1])\n",
    "# print(q2_model_part2.layers[2].variables)\n",
    "# print(q_weights_1_1)\n",
    "\n",
    "for i, idx in enumerate(q_idx_new_part2):\n",
    "    q2_model_part2.layers[idx].set_weights(q_weights_2[i])\n",
    "\n",
    "# for variable in q2_model_part1.layers[2].variables[1:]:\n",
    "#     print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense_last/bias:0' shape=(10,) dtype=float32, numpy=\n",
      "array([-0.01815677,  0.01968499,  0.10201531, -0.01608334, -0.20346883,\n",
      "       -0.09949773,  0.05465699,  0.03644126,  0.17258494, -0.07113054],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'quant_dense_last/optimizer_step:0' shape=() dtype=int32, numpy=-1>\n",
      "<tf.Variable 'quant_dense_last/kernel_min:0' shape=() dtype=float32, numpy=-1.308446>\n",
      "<tf.Variable 'quant_dense_last/kernel_max:0' shape=() dtype=float32, numpy=1.308446>\n",
      "<tf.Variable 'quant_dense_last/pre_activation_min:0' shape=() dtype=float32, numpy=-14.458281>\n",
      "<tf.Variable 'quant_dense_last/pre_activation_max:0' shape=() dtype=float32, numpy=11.440342>\n"
     ]
    }
   ],
   "source": [
    "TARGET_LAYER = 9\n",
    "# for variable in q_aware_model.layers[TARGET_LAYER].variables[4:]:\n",
    "#     print(variable)\n",
    "for variable in q2_model_part2.layers[TARGET_LAYER].variables[1:]:\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original output\n",
      " [[4.1630726e-09 5.6541989e-12 5.6541989e-12 5.6541989e-12 4.1630726e-09\n",
      "  4.9333132e-10 7.9284503e-11 6.4615868e-08 9.9999988e-01 1.2305925e-09]]\n",
      "quantized model output\n",
      " [[1.7768173e-02 1.3565700e-04 2.3306436e-03 3.1608273e-03 6.2239671e-04\n",
      "  4.2867283e-03 1.7768173e-02 5.0724548e-01 4.1400111e-01 3.2680809e-02]]\n",
      "\n",
      "Unique difference quantized [-5.0724542e-01 -3.2680809e-02 -1.7768173e-02 -1.7768169e-02\n",
      " -4.2867279e-03 -3.1608273e-03 -2.3306436e-03 -6.2239252e-04\n",
      " -1.3565700e-04  5.8599877e-01]\n"
     ]
    }
   ],
   "source": [
    "TARGET_IMAGE = 100\n",
    "OUT_CHANNEL = 20\n",
    "\n",
    "out_original = q_aware_model(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out2_q1 = q2_model_part1(train_images[np.newaxis,TARGET_IMAGE])\n",
    "out2_q2 = q2_model_part2(out2_q1)\n",
    "\n",
    "print(\"original output\\n\", out_original .numpy())\n",
    "print(\"quantized model output\\n\", out2_q2.numpy())\n",
    "print(\"\\nUnique difference quantized\", np.unique((out_original - out2_q2).numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
