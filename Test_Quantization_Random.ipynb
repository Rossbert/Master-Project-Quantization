{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_functional_model(learning_rate : float) -> tf.keras.Model:\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu')(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu')(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu')(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\")(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_functional_model_kernel_regularization(learning_rate : float, regularization_rate : float) -> tf.keras.Model:\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate))(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\", \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate))(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_functional_model_kernel_bias_regularization(learning_rate : float, regularization_rate : float) -> tf.keras.Model:\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate))(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\", \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate))(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_functional_model_all_regularization(learning_rate : float, regularization_rate : float) -> tf.keras.Model:\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        activity_regularizer = tf.keras.regularizers.L2(regularization_rate))(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        activity_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu', \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        activity_regularizer = tf.keras.regularizers.L2(regularization_rate))(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\", \n",
    "                                        kernel_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        bias_regularizer = tf.keras.regularizers.L2(regularization_rate),\n",
    "                                        activity_regularizer = tf.keras.regularizers.L2(regularization_rate))(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_functional_model(0.01)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, acc = model.evaluate(test_images, test_labels)\n",
    "# print('Test accuracy : ', \"{:0.2%}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model - normal_model - 100 - 0.01 - Nonetime 0.10600519180297852\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3907 - accuracy: 0.8746\n",
      "model_1 - model_kernel_reg - 100 - 0.01 - 0.01time 0.14699721336364746\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.8376 - accuracy: 0.7930\n",
      "model_2 - model_kernel_bias_reg - 100 - 0.01 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8708 - accuracy: 0.7910\n",
      "model_3 - model_all_reg - 100 - 0.01 - 0.01time 0.0\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 2.3156 - accuracy: 0.1000\n",
      "model_4 - model_kernel_reg - 100 - 0.01 - 0.0021544346900318843time 0.18599987030029297\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5949 - accuracy: 0.8446\n",
      "model_5 - model_kernel_bias_reg - 100 - 0.01 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6431 - accuracy: 0.8350\n",
      "model_6 - model_all_reg - 100 - 0.01 - 0.0021544346900318843time 0.0009987354278564453\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8582 - accuracy: 0.8399\n",
      "model_7 - model_kernel_reg - 100 - 0.01 - 0.0004641588833612782time 0.1269996166229248\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.8643\n",
      "model_8 - model_kernel_bias_reg - 100 - 0.01 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.8718\n",
      "model_9 - model_all_reg - 100 - 0.01 - 0.0004641588833612782time 0.0010042190551757812\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5786 - accuracy: 0.8526\n",
      "model_10 - model_kernel_reg - 100 - 0.01 - 0.0001time 0.1770017147064209\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4215 - accuracy: 0.8781\n",
      "model_11 - model_kernel_bias_reg - 100 - 0.01 - 0.0001time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4284 - accuracy: 0.8742\n",
      "model_12 - model_all_reg - 100 - 0.01 - 0.0001time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4324 - accuracy: 0.8758\n",
      "model_13 - normal_model - 100 - 0.0017782794 - Nonetime 0.03600001335144043\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3159 - accuracy: 0.8966\n",
      "model_14 - model_kernel_reg - 100 - 0.0017782794 - 0.01time 0.1629960536956787\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7884 - accuracy: 0.8203\n",
      "model_15 - model_kernel_bias_reg - 100 - 0.0017782794 - 0.01time 0.0\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8000 - accuracy: 0.8204\n",
      "model_16 - model_all_reg - 100 - 0.0017782794 - 0.01time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6603 - accuracy: 0.7390\n",
      "model_17 - model_kernel_reg - 100 - 0.0017782794 - 0.0021544346900318843time 0.11099839210510254\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5550 - accuracy: 0.8506\n",
      "model_18 - model_kernel_bias_reg - 100 - 0.0017782794 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5423 - accuracy: 0.8672\n",
      "model_19 - model_all_reg - 100 - 0.0017782794 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7878 - accuracy: 0.8630\n",
      "model_20 - model_kernel_reg - 100 - 0.0017782794 - 0.0004641588833612782time 0.11899709701538086\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4306 - accuracy: 0.8815\n",
      "model_21 - model_kernel_bias_reg - 100 - 0.0017782794 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.8965\n",
      "model_22 - model_all_reg - 100 - 0.0017782794 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.4573 - accuracy: 0.8979\n",
      "model_23 - model_kernel_reg - 100 - 0.0017782794 - 0.0001time 0.11699962615966797\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3219 - accuracy: 0.9063\n",
      "model_24 - model_kernel_bias_reg - 100 - 0.0017782794 - 0.0001time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3288 - accuracy: 0.9016\n",
      "model_25 - model_all_reg - 100 - 0.0017782794 - 0.0001time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3661 - accuracy: 0.9042\n",
      "model_26 - normal_model - 100 - 0.00031622776 - Nonetime 0.04199934005737305\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8861\n",
      "model_27 - model_kernel_reg - 100 - 0.00031622776 - 0.01time 0.12200021743774414\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7929 - accuracy: 0.8271\n",
      "model_28 - model_kernel_bias_reg - 100 - 0.00031622776 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8127 - accuracy: 0.8084\n",
      "model_29 - model_all_reg - 100 - 0.00031622776 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.6605 - accuracy: 0.7501\n",
      "model_30 - model_kernel_reg - 100 - 0.00031622776 - 0.0021544346900318843time 0.1419990062713623\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.5369 - accuracy: 0.8614\n",
      "model_31 - model_kernel_bias_reg - 100 - 0.00031622776 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5232 - accuracy: 0.8665\n",
      "model_32 - model_all_reg - 100 - 0.00031622776 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8014 - accuracy: 0.8617\n",
      "model_33 - model_kernel_reg - 100 - 0.00031622776 - 0.0004641588833612782time 0.10900044441223145\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4094 - accuracy: 0.8839\n",
      "model_34 - model_kernel_bias_reg - 100 - 0.00031622776 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.8777\n",
      "model_35 - model_all_reg - 100 - 0.00031622776 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.4608 - accuracy: 0.8925\n",
      "model_36 - model_kernel_reg - 100 - 0.00031622776 - 0.0001time 0.10399651527404785\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.8865\n",
      "model_37 - model_kernel_bias_reg - 100 - 0.00031622776 - 0.0001time 0.0\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3620 - accuracy: 0.8792\n",
      "model_38 - model_all_reg - 100 - 0.00031622776 - 0.0001time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3489 - accuracy: 0.8969\n",
      "model_39 - normal_model - 100 - 5.6234134e-05 - Nonetime 0.043001651763916016\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8385\n",
      "model_40 - model_kernel_reg - 100 - 5.6234134e-05 - 0.01time 0.11999869346618652\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9800 - accuracy: 0.7991\n",
      "model_41 - model_kernel_bias_reg - 100 - 5.6234134e-05 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9848 - accuracy: 0.7992\n",
      "model_42 - model_all_reg - 100 - 5.6234134e-05 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 1.7630 - accuracy: 0.7255\n",
      "model_43 - model_kernel_reg - 100 - 5.6234134e-05 - 0.0021544346900318843time 0.12599706649780273\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7108 - accuracy: 0.8285\n",
      "model_44 - model_kernel_bias_reg - 100 - 5.6234134e-05 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.7031 - accuracy: 0.8303\n",
      "model_45 - model_all_reg - 100 - 5.6234134e-05 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9087 - accuracy: 0.8331\n",
      "model_46 - model_kernel_reg - 100 - 5.6234134e-05 - 0.0004641588833612782time 0.12200093269348145\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.5410 - accuracy: 0.8368\n",
      "model_47 - model_kernel_bias_reg - 100 - 5.6234134e-05 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5523 - accuracy: 0.8309\n",
      "model_48 - model_all_reg - 100 - 5.6234134e-05 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5999 - accuracy: 0.8525\n",
      "model_49 - model_kernel_reg - 100 - 5.6234134e-05 - 0.0001time 0.11900448799133301\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4636 - accuracy: 0.8465\n",
      "model_50 - model_kernel_bias_reg - 100 - 5.6234134e-05 - 0.0001time 0.0009992122650146484\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.8352\n",
      "model_51 - model_all_reg - 100 - 5.6234134e-05 - 0.0001time 0.0009984970092773438\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4894 - accuracy: 0.8539\n",
      "model_52 - normal_model - 100 - 1e-05 - Nonetime 0.04500174522399902\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6643 - accuracy: 0.7541\n",
      "model_53 - model_kernel_reg - 100 - 1e-05 - 0.01time 0.21500301361083984\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.4477 - accuracy: 0.7315\n",
      "model_54 - model_kernel_bias_reg - 100 - 1e-05 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.4668 - accuracy: 0.7354\n",
      "model_55 - model_all_reg - 100 - 1e-05 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.1439 - accuracy: 0.6135\n",
      "model_56 - model_kernel_reg - 100 - 1e-05 - 0.0021544346900318843time 0.2239990234375\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9379 - accuracy: 0.7590\n",
      "model_57 - model_kernel_bias_reg - 100 - 1e-05 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9298 - accuracy: 0.7563\n",
      "model_58 - model_all_reg - 100 - 1e-05 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3040 - accuracy: 0.7464\n",
      "model_59 - model_kernel_reg - 100 - 1e-05 - 0.0004641588833612782time 0.18619084358215332\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.7294 - accuracy: 0.7602\n",
      "model_60 - model_kernel_bias_reg - 100 - 1e-05 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7507 - accuracy: 0.7554\n",
      "model_61 - model_all_reg - 100 - 1e-05 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.9410 - accuracy: 0.7546\n",
      "model_62 - model_kernel_reg - 100 - 1e-05 - 0.0001time 0.1230006217956543\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6733 - accuracy: 0.7550\n",
      "model_63 - model_kernel_bias_reg - 100 - 1e-05 - 0.0001time 0.0010018348693847656\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6738 - accuracy: 0.7611\n",
      "model_64 - model_all_reg - 100 - 1e-05 - 0.0001time 0.0\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7966 - accuracy: 0.7568\n",
      "model_65 - normal_model - 150 - 0.01 - Nonetime 0.07100105285644531\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3675 - accuracy: 0.8894\n",
      "model_66 - model_kernel_reg - 150 - 0.01 - 0.01time 0.1549994945526123\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.8234 - accuracy: 0.8045\n",
      "model_67 - model_kernel_bias_reg - 150 - 0.01 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8765 - accuracy: 0.7925\n",
      "model_68 - model_all_reg - 150 - 0.01 - 0.01time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.1000\n",
      "model_69 - model_kernel_reg - 150 - 0.01 - 0.0021544346900318843time 0.1679997444152832\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5690 - accuracy: 0.8518\n",
      "model_70 - model_kernel_bias_reg - 150 - 0.01 - 0.0021544346900318843time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5806 - accuracy: 0.8605\n",
      "model_71 - model_all_reg - 150 - 0.01 - 0.0021544346900318843time 0.0010008811950683594\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8455 - accuracy: 0.8474\n",
      "model_72 - model_kernel_reg - 150 - 0.01 - 0.0004641588833612782time 0.12599921226501465\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4450 - accuracy: 0.8755\n",
      "model_73 - model_kernel_bias_reg - 150 - 0.01 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4849 - accuracy: 0.8674\n",
      "model_74 - model_all_reg - 150 - 0.01 - 0.0004641588833612782time 0.0\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5329 - accuracy: 0.8743\n",
      "model_75 - model_kernel_reg - 150 - 0.01 - 0.0001time 0.200303316116333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m model_kernel_bias_reg \u001b[38;5;241m=\u001b[39m get_functional_model_kernel_bias_regularization(learning_rate, regularization_rate)\n\u001b[0;32m     43\u001b[0m model_all_reg \u001b[38;5;241m=\u001b[39m get_functional_model_all_regularization(learning_rate, regularization_rate)\n\u001b[1;32m---> 44\u001b[0m performance_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_performance_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_kernel_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_kernel_reg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization_rate\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     45\u001b[0m performance_data\u001b[38;5;241m.\u001b[39mappend(get_performance_data(model_kernel_bias_reg, batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_kernel_bias_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m, regularization_rate))\n\u001b[0;32m     46\u001b[0m performance_data\u001b[38;5;241m.\u001b[39mappend(get_performance_data(model_all_reg, batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_all_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m, regularization_rate))\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mget_performance_data\u001b[1;34m(model, batch_size, model_type, regularization_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m entry \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m train_log : tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mHistory\n\u001b[1;32m---> 12\u001b[0m train_log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     19\u001b[0m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-2, -5, 5, base = 10)\n",
    "regularization_rates = np.logspace(-2, -4, 4)\n",
    "# batch_sizes = np.arange(10, 250 + 1, 40)\n",
    "batch_sizes = np.array([100, 150, 200])\n",
    "epochs = 10\n",
    "last_time = time.time()\n",
    "def get_performance_data(model: tf.keras.Model, batch_size : int, model_type : str, regularization_rate : int = None) -> dict:\n",
    "    global last_time\n",
    "    print(model.name +\" - \"+ model_type + \" - \" + str(batch_size) + \" - \" + str(model.optimizer._learning_rate.numpy()) + \" - \" + str(regularization_rate) + \"time \" + str(time.time() - last_time))\n",
    "    entry = {}\n",
    "    train_log : tf.keras.callbacks.History\n",
    "    train_log = model.fit(train_images, train_labels,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_split = 0.1,\n",
    "        verbose = 0)\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    entry['name'] = model.name\n",
    "    entry['type'] = model_type\n",
    "    entry['learning_rate'] = model.optimizer._learning_rate.numpy()\n",
    "    entry['batch_size'] = batch_size\n",
    "    entry['regularization_rate'] = regularization_rate\n",
    "    entry['train_loss'] = train_log.history['loss']\n",
    "    entry['train_accuracy'] = train_log.history['accuracy']\n",
    "    entry['validation_loss'] = train_log.history['val_loss']\n",
    "    entry['validation_accuracy'] = train_log.history['val_accuracy']\n",
    "    entry['test_loss'] = test_loss\n",
    "    entry['test_accuracy'] = test_acc\n",
    "\n",
    "    last_time = time.time()\n",
    "    return entry\n",
    "\n",
    "performance_data = []\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        model = get_functional_model(learning_rate)\n",
    "        performance_data.append(get_performance_data(model, batch_size, \"normal_model\"))\n",
    "\n",
    "        for regularization_rate in regularization_rates:\n",
    "            model_kernel_reg = get_functional_model_kernel_regularization(learning_rate, regularization_rate)\n",
    "            model_kernel_bias_reg = get_functional_model_kernel_bias_regularization(learning_rate, regularization_rate)\n",
    "            model_all_reg = get_functional_model_all_regularization(learning_rate, regularization_rate)\n",
    "            performance_data.append(get_performance_data(model_kernel_reg, batch_size, \"model_kernel_reg\", regularization_rate))\n",
    "            performance_data.append(get_performance_data(model_kernel_bias_reg, batch_size, \"model_kernel_bias_reg\", regularization_rate))\n",
    "            performance_data.append(get_performance_data(model_all_reg, batch_size, \"model_all_reg\", regularization_rate))\n",
    "\n",
    "# data = pd.DataFrame(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(performance_data)\n",
    "# data = pd.DataFrame(performance_data)\n",
    "# data.to_csv('Test_File_2.csv')\n",
    "data2 = pd.read_csv('Test_File_2.csv')\n",
    "# print(data2)\n",
    "performance_data2 = data2.values.tolist()\n",
    "# print(performance_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, acc = model.evaluate(test_images, test_labels)\n",
    "# print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_official_1\"\n",
    "# model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model_v3\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_official_1\"\n",
    "# model = tf.keras.models.load_model(save_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model = tfmot.quantization.keras.quantize_model(model)\n",
    "q_aware_model.compile(optimizer = 'adam', \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = q_aware_model.fit(train_images, train_labels,\n",
    "    batch_size = 128,\n",
    "    # epochs = 15,\n",
    "    epochs = 1,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q4_func\"\n",
    "# q_aware_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q4_func\"\n",
    "q_aware_model : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tf.keras.models.load_model(save_path)\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(q_aware_model.layers)):\n",
    "    print(\"Layer : \", i, q_aware_model.layers[i].name,\" - params : \", len(q_aware_model.layers[i].variables))#, len(q_aware_model.layers[i]), \"Weights len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_width = 8\n",
    "quantized_and_dequantized = OrderedDict()\n",
    "quantized = OrderedDict()\n",
    "new_quantized_and_dequantized = OrderedDict()\n",
    "new_quantized = OrderedDict()\n",
    "layer_index_list = []\n",
    "key_index_list = []\n",
    "\n",
    "layer : tfmot.quantization.keras.QuantizeWrapperV2\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    quantizer : tfmot.quantization.keras.quantizers.Quantizer\n",
    "    weight : tf.Variable\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "\n",
    "            key = weight.name[:-2]\n",
    "            layer_index_list.append(i)\n",
    "            key_index_list.append(key)\n",
    "            quantized_and_dequantized[key] = quantizer(inputs = weight, training = False, weights = quantizer_vars)\n",
    "            quantized[key] = np.round(quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "            if \"conv2d\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars_per_channel(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "            elif \"dense\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "for key in quantized:\n",
    "    # print(\"Fake Quantized\")\n",
    "    print(key)\n",
    "    if \"dense\" not in key:\n",
    "        # print(quantized_and_dequantized[key][:,:,0,0])\n",
    "        print(quantized[key][:,:,0,0])\n",
    "    else:\n",
    "        # print(quantized_and_dequantized[key][:,0])\n",
    "        print(quantized[key][:,0])\n",
    "\n",
    "    # print(\"New Fake Quantized\")\n",
    "    # print(key)\n",
    "    # if \"dense\" not in key:\n",
    "    #     print(new_quantized_and_dequantized[key][:,:,0,0])\n",
    "    #     print(new_quantized[key][:,:,0,0])\n",
    "    # else:\n",
    "    #     print(new_quantized_and_dequantized[key][:,0])\n",
    "    #     print(new_quantized[key][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_quantize_function(input, min_var, max_var, bits, narrow_range = False):\n",
    "    if not narrow_range:\n",
    "        scale = (max_var - min_var) / (2**bits - 1)\n",
    "    else:\n",
    "        scale = (max_var - min_var) / (2**bits - 2)\n",
    "    min_adj = scale * np.round(min_var / scale)\n",
    "    max_adj = max_var + min_adj - min_var\n",
    "    # print(\"Scale : \", scale)\n",
    "    return scale * np.round(input / scale)\n",
    "\n",
    "for idx, layer_index in enumerate(layer_index_list):\n",
    "    m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if key_index_list[idx] in variable.name}\n",
    "    kernel = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].trainable_variables) if \"kernel\" in variable.name}\n",
    "    min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "    max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "    min_var = m_vars[min_key]\n",
    "    max_var = m_vars[max_key]\n",
    "\n",
    "    kernel_index = 0\n",
    "    self_quantized_and_dequantized = self_quantize_function(q_aware_model.layers[layer_index].trainable_variables[kernel_index], min_var, max_var, bit_width, narrow_range = True)\n",
    "    \n",
    "    print(key_index_list[idx])\n",
    "    # print(\"Self Quantized\")\n",
    "    if \"dense\" not in key_index_list[idx]:\n",
    "        # print(self_quantized_and_dequantized[:,:,0,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,:,0,0])\n",
    "    else:\n",
    "        # print(self_quantized_and_dequantized[:,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 2\n",
    "print(q_aware_model.layers[l].quantize_config.get_config())\n",
    "print(q_aware_model.layers[l].quantize_config.activation_quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to TF Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter: tf.lite.Interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    # print(\"Shape : \", test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "    test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "    # print(\"New Shape : \", test_image.shape)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content = quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Output Shape: \", output_details[0]['shape'])\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "quant_file = 'quant_model_q4_func.tflite'\n",
    "save_path = save_dir + quant_file\n",
    "# with open(save_path, 'wb') as f:\n",
    "#   f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_index = 10\n",
    "test_image = test_images[ind_index]\n",
    "test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "interpreter.invoke()\n",
    "output_array = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(output_array.shape)\n",
    "digit = np.argmax(output_array[0])\n",
    "probability = max(output_array[0])\n",
    "print(\"Input index : \", test_labels[ind_index])\n",
    "print(\"Output index : \", digit, \"{0:.2%}\".format(probability))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
