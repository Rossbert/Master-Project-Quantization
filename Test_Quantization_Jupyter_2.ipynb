{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from collections import OrderedDict\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_functional_model():\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu')(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu')(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu')(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\")(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_functional_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = model.fit(train_images, train_labels,\n",
    "    batch_size = 64,\n",
    "    epochs = 15,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_v3\"\n",
    "# model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model_v3\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_v3\"\n",
    "# model = tf.keras.models.load_model(save_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model = tfmot.quantization.keras.quantize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model.compile(optimizer = 'adam', \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = q_aware_model.fit(train_images, train_labels,\n",
    "    batch_size = 128,\n",
    "    # epochs = 15,\n",
    "    epochs = 1,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q4_func\"\n",
    "# q_aware_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3154 - accuracy: 0.9038\n",
      "Test accuracy :  90.38%\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q4_func\"\n",
    "q_aware_model : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tf.keras.models.load_model(save_path)\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer :  0 input_2  - params :  0\n",
      "Layer :  1 quantize_layer  - params :  3\n",
      "Layer :  2 quant_conv2d_3  - params :  6\n",
      "Layer :  3 quant_max_pooling2d_3  - params :  1\n",
      "Layer :  4 quant_conv2d_4  - params :  6\n",
      "Layer :  5 quant_max_pooling2d_4  - params :  1\n",
      "Layer :  6 quant_conv2d_5  - params :  6\n",
      "Layer :  7 quant_max_pooling2d_5  - params :  1\n",
      "Layer :  8 quant_flatten_1  - params :  1\n",
      "Layer :  9 quant_dense_last  - params :  7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(q_aware_model.layers)):\n",
    "    print(\"Layer : \", i, q_aware_model.layers[i].name,\" - params : \", len(q_aware_model.layers[i].variables))#, len(q_aware_model.layers[i]), \"Weights len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_3/kernel\n",
      "[[ 121.  127.   59.   68.    9.]\n",
      " [ -16.   53.   73.   37.  -24.]\n",
      " [  16.   23.    4.  -30.  -89.]\n",
      " [ -68.  -21.  -11.    0.   -7.]\n",
      " [-112. -108.  -36.   22.  -51.]]\n",
      "conv2d_4/kernel\n",
      "[[-70.  20.  17.   1.  29.]\n",
      " [-61.  -6. -15.  -3. -37.]\n",
      " [  4. -46.  13.  22.  -2.]\n",
      " [-48. -49.  16.  57.  16.]\n",
      " [-36.   9. -16. -27.  -3.]]\n",
      "conv2d_5/kernel\n",
      "[[ -1. -32. -22.]\n",
      " [ -8. -22.  51.]\n",
      " [-70.   2. -76.]]\n",
      "dense_last/kernel\n",
      "[-22.  22.  22. -28.  30. -28.  69. -45.  23.   4.  22. -18. -30. -57.\n",
      "  -9. -66. -83. -16. -17. -54.  22.  32.  57. -49.   4. -12.  29.  -9.\n",
      "  -8. -21.  33.   1. -47.  -8.   3.  18. -18.   8.   3.   3. -42.  -9.\n",
      "  23. -23.  37.   2. -24.  23.  -3.   5.  34.   4.   3.  36. -31. -21.\n",
      "  34. -41. -43.  40. -37.  29. -31. -19.   6. -24.  61.  14.  13.  34.\n",
      " -42.   6.  -9. -47.  28.  12. -28. -20.  26.  -5.  10. -21.  22. -15.\n",
      " -10.  36.  29.  48. -35.   0. -70. -22. -39.   1.  30.  13.]\n"
     ]
    }
   ],
   "source": [
    "bit_width = 8\n",
    "quantized_and_dequantized = OrderedDict()\n",
    "quantized = OrderedDict()\n",
    "new_quantized_and_dequantized = OrderedDict()\n",
    "new_quantized = OrderedDict()\n",
    "layer_index_list = []\n",
    "key_index_list = []\n",
    "\n",
    "layer : tfmot.quantization.keras.QuantizeWrapperV2\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    quantizer : tfmot.quantization.keras.quantizers.Quantizer\n",
    "    weight : tf.Variable\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "\n",
    "            key = weight.name[:-2]\n",
    "            layer_index_list.append(i)\n",
    "            key_index_list.append(key)\n",
    "            quantized_and_dequantized[key] = quantizer(inputs = weight, training = False, weights = quantizer_vars)\n",
    "            quantized[key] = np.round(quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "            if \"conv2d\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars_per_channel(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "            elif \"dense\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "for key in quantized:\n",
    "    # print(\"Fake Quantized\")\n",
    "    print(key)\n",
    "    if \"dense\" not in key:\n",
    "        # print(quantized_and_dequantized[key][:,:,0,0])\n",
    "        print(quantized[key][:,:,0,0])\n",
    "    else:\n",
    "        # print(quantized_and_dequantized[key][:,0])\n",
    "        print(quantized[key][:,0])\n",
    "\n",
    "    # print(\"New Fake Quantized\")\n",
    "    # print(key)\n",
    "    # if \"dense\" not in key:\n",
    "    #     print(new_quantized_and_dequantized[key][:,:,0,0])\n",
    "    #     print(new_quantized[key][:,:,0,0])\n",
    "    # else:\n",
    "    #     print(new_quantized_and_dequantized[key][:,0])\n",
    "    #     print(new_quantized[key][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_3/kernel\n",
      "[[ 121.  127.   59.   68.    9.]\n",
      " [ -16.   53.   73.   37.  -24.]\n",
      " [  16.   23.    4.  -30.  -89.]\n",
      " [ -68.  -21.  -11.    0.   -7.]\n",
      " [-112. -108.  -36.   22.  -51.]]\n",
      "conv2d_4/kernel\n",
      "[[-70.  20.  17.   1.  29.]\n",
      " [-61.  -6. -15.  -3. -37.]\n",
      " [  4. -46.  13.  22.  -2.]\n",
      " [-48. -49.  16.  57.  16.]\n",
      " [-36.   9. -16. -27.  -3.]]\n",
      "conv2d_5/kernel\n",
      "[[ -1. -32. -22.]\n",
      " [ -8. -22.  51.]\n",
      " [-70.   2. -76.]]\n",
      "dense_last/kernel\n",
      "[-22.  22.  22. -28.  30. -28.  69. -45.  23.   4.  22. -18. -30. -57.\n",
      "  -9. -66. -83. -16. -17. -54.  22.  32.  57. -49.   4. -12.  29.  -9.\n",
      "  -8. -21.  33.   1. -47.  -8.   3.  18. -18.   8.   3.   3. -42.  -9.\n",
      "  23. -23.  37.   2. -24.  23.  -3.   5.  34.   4.   3.  36. -31. -21.\n",
      "  34. -41. -43.  40. -37.  29. -31. -19.   6. -24.  61.  14.  13.  34.\n",
      " -42.   6.  -9. -47.  28.  12. -28. -20.  26.  -5.  10. -21.  22. -15.\n",
      " -10.  36.  29.  48. -35.  -0. -70. -22. -39.   1.  30.  13.]\n"
     ]
    }
   ],
   "source": [
    "def self_quantize_function(input, min_var, max_var, bits, narrow_range = False):\n",
    "    if not narrow_range:\n",
    "        scale = (max_var - min_var) / (2**bits - 1)\n",
    "    else:\n",
    "        scale = (max_var - min_var) / (2**bits - 2)\n",
    "    min_adj = scale * np.round(min_var / scale)\n",
    "    max_adj = max_var + min_adj - min_var\n",
    "    # print(\"Scale : \", scale)\n",
    "    return scale * np.round(input / scale)\n",
    "\n",
    "for idx, layer_index in enumerate(layer_index_list):\n",
    "    m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if key_index_list[idx] in variable.name}\n",
    "    kernel = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].trainable_variables) if \"kernel\" in variable.name}\n",
    "    min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "    max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "    min_var = m_vars[min_key]\n",
    "    max_var = m_vars[max_key]\n",
    "\n",
    "    kernel_index = 0\n",
    "    self_quantized_and_dequantized = self_quantize_function(q_aware_model.layers[layer_index].trainable_variables[kernel_index], min_var, max_var, bit_width, narrow_range = True)\n",
    "    \n",
    "    print(key_index_list[idx])\n",
    "    # print(\"Self Quantized\")\n",
    "    if \"dense\" not in key_index_list[idx]:\n",
    "        # print(self_quantized_and_dequantized[:,:,0,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,:,0,0])\n",
    "    else:\n",
    "        # print(self_quantized_and_dequantized[:,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight_attrs': ['kernel'], 'activation_attrs': ['activation'], 'quantize_output': False}\n",
      "<tensorflow_model_optimization.python.core.quantization.keras.quantizers.MovingAverageQuantizer object at 0x000002880459F3D0>\n"
     ]
    }
   ],
   "source": [
    "l = 2\n",
    "print(q_aware_model.layers[l].quantize_config.get_config())\n",
    "print(q_aware_model.layers[l].quantize_config.activation_quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_4_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpr6l4hsb7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpr6l4hsb7\\assets\n",
      "c:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Conversion to TF Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter: tf.lite.Interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    # print(\"Shape : \", test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "    test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "    # print(\"New Shape : \", test_image.shape)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  [ 1 28 28  1]\n",
      "Output Shape:  [ 1 10]\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9038\n",
      "Quant TF test accuracy: 0.9038000106811523\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content = quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Output Shape: \", output_details[0]['shape'])\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "quant_file = 'quant_model_q4_func.tflite'\n",
    "save_path = save_dir + quant_file\n",
    "# with open(save_path, 'wb') as f:\n",
    "#   f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input index :  4\n",
      "Output index :  4 99.61%\n"
     ]
    }
   ],
   "source": [
    "ind_index = 10\n",
    "test_image = test_images[ind_index]\n",
    "test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "interpreter.invoke()\n",
    "output_array = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(output_array.shape)\n",
    "digit = np.argmax(output_array[0])\n",
    "probability = max(output_array[0])\n",
    "print(\"Input index : \", test_labels[ind_index])\n",
    "print(\"Output index : \", digit, \"{0:.2%}\".format(probability))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
