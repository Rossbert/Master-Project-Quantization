{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import ast\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH_Q_AWARE = \"./model/\" + \"model_q_aware_final_01\"\n",
    "LOAD_TFLITE_PATH = \"./model/\" + 'tflite_final_01.tflite'\n",
    "# Load Q Aware model\n",
    "q_aware_model : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tf.keras.models.load_model(LOAD_PATH_Q_AWARE)\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(LOAD_TFLITE_PATH)\n",
    "\n",
    "def bit_flipper(value : int, bit_pos : int) -> int:\n",
    "    \"\"\" Random bit flipper \n",
    "    -\n",
    "    Obtains a value and bit position and flips it.\n",
    "    - All values are in 8 bits, MSB have higher probability of getting flipped\n",
    "    - It is assumed value is a signed 8 bit number \"\"\"\n",
    "    # Negative 2 Complement conversion\n",
    "    if value < 0:\n",
    "        value = (-value ^ 0xFF) + 1\n",
    "    flip_mask = 1 << bit_pos\n",
    "    flipped_value = value ^ flip_mask\n",
    "    # Negative back conversion 2 Complement\n",
    "    if flipped_value >= 128:\n",
    "        flipped_value = -((flipped_value ^ 0xFF) + 1)\n",
    "    return flipped_value\n",
    "\n",
    "def evaluate_model(interpreter: tf.lite.Interpreter) -> Tuple[float, float]:\n",
    "    \"\"\" Evaluate TFLite Model:\n",
    "    -\n",
    "    Receives the interpreter and returns a tuple of loss and accuracy.\n",
    "    \"\"\"\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    predictions = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "        test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        predictions.append(np.copy(output()[0]))\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    predictions = np.array(predictions)\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()(test_labels, predictions)\n",
    "\n",
    "    loss = scce.numpy()\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of both models\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Q Aware model test accuracy: ', \"{:0.2%}\".format(q_aware_test_acc))\n",
    "print('Q Aware model test loss: ', q_aware_test_loss)\n",
    "interpreter.allocate_tensors()\n",
    "tflite_loss, tflite_accuracy = evaluate_model(interpreter)\n",
    "print('TFLite model test accuracy: ', \"{:0.2%}\".format(tflite_accuracy))\n",
    "print('TFLite model test loss: ', tflite_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIT_WIDTH = 8\n",
    "quantized_and_dequantized = OrderedDict()\n",
    "quantized = OrderedDict()\n",
    "layer_index_list = []\n",
    "keys_list = []\n",
    "\n",
    "layer : tfmot.quantization.keras.QuantizeWrapperV2\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    quantizer : tfmot.quantization.keras.quantizers.Quantizer\n",
    "    weight : tf.Variable\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "\n",
    "            key = weight.name[:-2]\n",
    "            layer_index_list.append(i)\n",
    "            keys_list.append(key)\n",
    "            quantized_and_dequantized[key] = quantizer(inputs = weight, training = False, weights = quantizer_vars)\n",
    "            quantized[key] = np.round(quantized_and_dequantized[key] / max_var * (2**(BIT_WIDTH-1)-1))\n",
    "\n",
    "for key in quantized:\n",
    "    # print(\"Fake Quantized\")\n",
    "    print(key, quantized[key].shape)\n",
    "    if \"dense\" not in key:\n",
    "        # print(quantized_and_dequantized[key][:,:,0,0])\n",
    "        print(quantized[key][:,:,0,0])\n",
    "    else:\n",
    "        # print(quantized_and_dequantized[key][:,0])\n",
    "        print(quantized[key][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_idx = 0 \n",
    "key = keys_list[kernel_idx]\n",
    "print(type(quantized[key][:,:,0,29]))\n",
    "print(quantized[key][:,:,0,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Performance.csv')\n",
    "layer_affected_list = []\n",
    "kernel_index_list = []\n",
    "layer_affected_index_list = []\n",
    "position_disrupted_list = []\n",
    "bit_flipped_list = []\n",
    "row : pd.Series\n",
    "for index, row in df.iterrows():\n",
    "    layer_affected_list.append(row['layer_affected'])\n",
    "    try:\n",
    "        kernel_index_list.append(int(row['kernel_index']))\n",
    "    except:\n",
    "        kernel_index_list.append(-1)\n",
    "    try:\n",
    "        layer_affected_index_list.append(int(row['layer_affected_index']))\n",
    "    except:\n",
    "        layer_affected_index_list.append(-1)\n",
    "    try:\n",
    "        position_disrupted_list.append(ast.literal_eval(row['position_disrupted']))\n",
    "    except:\n",
    "        position_disrupted_list.append(tuple())\n",
    "    try:\n",
    "        bit_flipped_list.append(int(row['bit_disrupted']))\n",
    "    except:\n",
    "        bit_flipped_list.append(-1)\n",
    "\n",
    "BIT_WIDTH = 8\n",
    "T_VARIABLES_KERNEL_INDEX = 0\n",
    "out_list = []\n",
    "\n",
    "pos = 2013\n",
    "print(position_disrupted_list[pos])\n",
    "print(bit_flipped_list[pos])\n",
    "print(df['quantized_value'][pos])\n",
    "print(quantized[key][position_disrupted_list[pos]])\n",
    "for i, key in enumerate(layer_affected_list):\n",
    "    print(\"Index\", i)\n",
    "    entry = {}\n",
    "    position = position_disrupted_list[i]\n",
    "    if len(position) > 1:\n",
    "        q_aware_copy : tf.keras.Model\n",
    "        # Load Q Aware model copy\n",
    "        with tfmot.quantization.keras.quantize_scope():\n",
    "            q_aware_copy = tf.keras.models.load_model(LOAD_PATH_Q_AWARE)\n",
    "\n",
    "        if \"dense\" not in key:\n",
    "            # It is a convolutional layer\n",
    "            kernel_row = position[0]\n",
    "            kernel_column = position[1]\n",
    "            in_channel = position[2]\n",
    "            out_channel = position[3]\n",
    "            kernel_position = (slice(None), slice(None), in_channel, out_channel)\n",
    "            value_position = (kernel_row, kernel_column)\n",
    "        else:\n",
    "            # It is a fully connected layer\n",
    "            kernel_row = None\n",
    "            kernel_column = None\n",
    "            in_channel = position[0]\n",
    "            out_channel = position[1]\n",
    "            kernel_position = (slice(None), slice(None)) # This slice takes the whole densely connected kernel\n",
    "            value_position = (in_channel, out_channel)\n",
    "\n",
    "        kernel_idx = kernel_index_list[i]\n",
    "        layer_index = layer_index_list[kernel_idx]\n",
    "        m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if keys_list[kernel_idx] in variable.name}\n",
    "        min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "        max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "        if \"dense\" not in key:\n",
    "            # Convolutional layers max is divided per channels\n",
    "            min_var = m_vars[min_key][out_channel]\n",
    "            max_var = m_vars[max_key][out_channel]\n",
    "        else:\n",
    "            # Fully connected layer has only 1 max value for the kernel\n",
    "            min_var = m_vars[min_key]\n",
    "            max_var = m_vars[max_key]\n",
    "\n",
    "        flipped_int_kernel_value = bit_flipper(int(quantized[key][position]), bit_flipped_list[i])\n",
    "        flipped_float_kernel_val = flipped_int_kernel_value * max_var.numpy() / (2**(BIT_WIDTH - 1) - 1)\n",
    "        full_kernel = q_aware_copy.layers[layer_index].trainable_variables[T_VARIABLES_KERNEL_INDEX].numpy()\n",
    "        update_kernel = np.copy(full_kernel)\n",
    "        update_kernel[position] = flipped_float_kernel_val\n",
    "        q_aware_copy.layers[layer_index].trainable_variables[T_VARIABLES_KERNEL_INDEX].assign(update_kernel)\n",
    "        # Laplacian calculation\n",
    "        kernel = full_kernel[kernel_position]\n",
    "        original_laplacian = sp.ndimage.laplace(kernel)\n",
    "        new_laplacian = sp.ndimage.laplace(update_kernel[kernel_position])\n",
    "        int_kernel = np.copy(quantized[key][kernel_position]) # Important to avoid modifying the original values\n",
    "        original_int_laplacian = sp.ndimage.laplace(int_kernel)\n",
    "        int_kernel[value_position] = flipped_int_kernel_value\n",
    "        new_int_laplacian = sp.ndimage.laplace(int_kernel)    \n",
    "        \n",
    "        # Conversion of new model to TF Lite model\n",
    "        new_converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_copy)\n",
    "        new_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        new_tflite_model = new_converter.convert()\n",
    "        new_interpreter = tf.lite.Interpreter(model_content = new_tflite_model)\n",
    "\n",
    "        # Check new accuracy\n",
    "        q_copy_test_loss, q_copy_test_acc = q_aware_copy.evaluate(test_images, test_labels, verbose = 0)\n",
    "        new_interpreter.allocate_tensors()\n",
    "        new_tflite_loss, new_tflite_accuracy = evaluate_model(new_interpreter)\n",
    "\n",
    "        entry['position'] = position\n",
    "        entry['min_var'] = min_var.numpy()\n",
    "        entry['max_var'] = max_var.numpy()\n",
    "        entry['original_weight_value'] = full_kernel[position]\n",
    "        entry['quantized_value'] = quantized[key][position]\n",
    "        entry['bit_disrupted'] = bit_flipped_list[i]\n",
    "        entry['flipped_quantized_value'] = flipped_int_kernel_value\n",
    "        entry['flipped_weight_value'] = flipped_float_kernel_val\n",
    "        entry['q_aware_accuracy'] = q_copy_test_acc\n",
    "        entry['tflite_accuracy'] = new_tflite_accuracy\n",
    "        entry['q_aware_acc_degradation'] = q_copy_test_acc - q_aware_test_acc\n",
    "        entry['tflite_acc_degradation'] = new_tflite_accuracy - tflite_accuracy\n",
    "        entry['q_aware_loss'] = q_copy_test_loss\n",
    "        entry['tflite_loss'] = new_tflite_loss\n",
    "        entry['original_laplacian'] = original_laplacian[value_position]\n",
    "        entry['modified_laplacian'] = new_laplacian[value_position]\n",
    "        entry['original_int_laplacian'] = original_int_laplacian[value_position]\n",
    "        entry['modified_int_laplacian'] = new_int_laplacian[value_position]\n",
    "        entry['abs_laplacian_diff'] = np.abs(entry['original_laplacian'] - entry['modified_laplacian'])\n",
    "        entry['abs_int_laplacian_diff'] = np.abs(entry['original_int_laplacian'] - entry['modified_int_laplacian'])\n",
    "    else:\n",
    "        entry['position'] = None\n",
    "        entry['min_var'] = None\n",
    "        entry['max_var'] = None\n",
    "        entry['original_weight_value'] = None\n",
    "        entry['quantized_value'] = None\n",
    "        entry['bit_disrupted'] = None\n",
    "        entry['flipped_quantized_value'] = None\n",
    "        entry['flipped_weight_value'] = None\n",
    "        entry['q_aware_accuracy'] = q_aware_test_acc\n",
    "        entry['tflite_accuracy'] = tflite_accuracy\n",
    "        entry['q_aware_acc_degradation'] = None\n",
    "        entry['tflite_acc_degradation'] = None\n",
    "        entry['q_aware_loss'] = q_aware_test_loss\n",
    "        entry['tflite_loss'] = tflite_loss\n",
    "        entry['original_laplacian'] = None\n",
    "        entry['modified_laplacian'] = None\n",
    "        entry['original_int_laplacian'] = None\n",
    "        entry['modified_int_laplacian'] = None\n",
    "        entry['abs_laplacian_diff'] = None\n",
    "        entry['abs_int_laplacian_diff'] = None\n",
    "    out_list.append(entry)\n",
    "out_df = pd.DataFrame(out_list)\n",
    "out_df.to_csv('Max_Min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of loss calculation\n",
    "import time\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))\n",
    "print(\"Test accuracy : \", q_aware_test_loss)\n",
    "prediction = q_aware_model.predict(test_images)\n",
    "start_time = time.time()\n",
    "loss_self = np.array([-np.log(prediction[idx][test_labels[idx]]) for idx in range(test_images.shape[0])])\n",
    "print(\"Self calculated loss\")\n",
    "# print(loss_self)\n",
    "print(np.mean(loss_self))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(test_labels)\n",
    "# print(prediction)\n",
    "start_time = time.time()\n",
    "loss_1 = tf.keras.losses.sparse_categorical_crossentropy(test_labels, prediction)\n",
    "print(\"Function calculated loss\")\n",
    "# print(loss_1)\n",
    "print(np.mean(loss_1))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()(test_labels, prediction)\n",
    "print(\"Class calculated loss\")\n",
    "print(scce.numpy())\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
