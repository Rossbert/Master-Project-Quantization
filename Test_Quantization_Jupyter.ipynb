{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 96)          55392     \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 2, 2, 96)          0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 96)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                970       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,458\n",
      "Trainable params: 108,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 5, input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "    tf.keras.layers.Conv2D(64, 5),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "    tf.keras.layers.Conv2D(96, 3),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer = 'adam', \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer :  0 conv2d 2\n",
      "Layer :  1 re_lu 0\n",
      "Layer :  2 max_pooling2d 0\n",
      "Layer :  3 conv2d_1 2\n",
      "Layer :  4 re_lu_1 0\n",
      "Layer :  5 max_pooling2d_1 0\n",
      "Layer :  6 conv2d_2 2\n",
      "Layer :  7 re_lu_2 0\n",
      "Layer :  8 max_pooling2d_2 0\n",
      "Layer :  9 flatten 0\n",
      "Layer :  10 dense 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    print(\"Layer : \", i, model.layers[i].name, len(model.layers[i].get_weights()))#, len(q_aware_model.layers[i]), \"Weights len\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 2.3060 - accuracy: 0.1136\n",
      "Test accuracy :  11.36%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "844/844 [==============================] - 20s 23ms/step - loss: 0.5791 - accuracy: 0.7914 - val_loss: 0.4289 - val_accuracy: 0.8448\n",
      "Epoch 2/15\n",
      "844/844 [==============================] - 19s 23ms/step - loss: 0.3669 - accuracy: 0.8679 - val_loss: 0.3499 - val_accuracy: 0.8733\n",
      "Epoch 3/15\n",
      "844/844 [==============================] - 17s 20ms/step - loss: 0.3120 - accuracy: 0.8887 - val_loss: 0.3093 - val_accuracy: 0.8892\n",
      "Epoch 4/15\n",
      "844/844 [==============================] - 19s 22ms/step - loss: 0.2810 - accuracy: 0.8974 - val_loss: 0.2964 - val_accuracy: 0.8905\n",
      "Epoch 5/15\n",
      "844/844 [==============================] - 18s 21ms/step - loss: 0.2542 - accuracy: 0.9068 - val_loss: 0.2885 - val_accuracy: 0.8933\n",
      "Epoch 6/15\n",
      "844/844 [==============================] - 18s 21ms/step - loss: 0.2338 - accuracy: 0.9147 - val_loss: 0.2731 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "844/844 [==============================] - 17s 20ms/step - loss: 0.2165 - accuracy: 0.9214 - val_loss: 0.2785 - val_accuracy: 0.9042\n",
      "Epoch 8/15\n",
      "844/844 [==============================] - 18s 21ms/step - loss: 0.2037 - accuracy: 0.9243 - val_loss: 0.2517 - val_accuracy: 0.9100\n",
      "Epoch 9/15\n",
      "844/844 [==============================] - 19s 22ms/step - loss: 0.1876 - accuracy: 0.9312 - val_loss: 0.2604 - val_accuracy: 0.9122\n",
      "Epoch 10/15\n",
      "844/844 [==============================] - 17s 21ms/step - loss: 0.1733 - accuracy: 0.9364 - val_loss: 0.2632 - val_accuracy: 0.9027\n",
      "Epoch 11/15\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.1594 - accuracy: 0.9409 - val_loss: 0.2695 - val_accuracy: 0.9017\n",
      "Epoch 12/15\n",
      "844/844 [==============================] - 18s 21ms/step - loss: 0.1466 - accuracy: 0.9463 - val_loss: 0.2758 - val_accuracy: 0.9077\n",
      "Epoch 13/15\n",
      "844/844 [==============================] - 16s 20ms/step - loss: 0.1372 - accuracy: 0.9500 - val_loss: 0.2702 - val_accuracy: 0.9105\n",
      "Epoch 14/15\n",
      "844/844 [==============================] - 17s 20ms/step - loss: 0.1276 - accuracy: 0.9537 - val_loss: 0.2616 - val_accuracy: 0.9130\n",
      "Epoch 15/15\n",
      "844/844 [==============================] - 16s 19ms/step - loss: 0.1154 - accuracy: 0.9583 - val_loss: 0.2914 - val_accuracy: 0.9098\n"
     ]
    }
   ],
   "source": [
    "train_log = model.fit(train_images, train_labels,\n",
    "    batch_size = 64,\n",
    "    epochs = 15,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.9052\n",
      "Test accuracy :  90.52%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_v2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_v2\"\n",
    "# model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.9080\n",
      "Test accuracy :  90.80%\n"
     ]
    }
   ],
   "source": [
    "# Load model_v2\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_v2\"\n",
    "# model = tf.keras.models.load_model(save_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model = tfmot.quantization.keras.quantize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_4 (QuantizeL  (None, 28, 28, 1)        3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_conv2d_9 (QuantizeWra  (None, 24, 24, 32)       833       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_re_lu_9 (QuantizeWrap  (None, 24, 24, 32)       3         \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_max_pooling2d_9 (Quan  (None, 12, 12, 32)       1         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv2d_10 (QuantizeWr  (None, 8, 8, 64)         51265     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_re_lu_10 (QuantizeWra  (None, 8, 8, 64)         3         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_max_pooling2d_10 (Qua  (None, 4, 4, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_11 (QuantizeWr  (None, 2, 2, 96)         55393     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_re_lu_11 (QuantizeWra  (None, 2, 2, 96)         3         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_max_pooling2d_11 (Qua  (None, 1, 1, 96)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_3 (QuantizeWr  (None, 96)               1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dense_3 (QuantizeWrap  (None, 10)               975       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,482\n",
      "Trainable params: 108,458\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model.compile(optimizer = 'adam', \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 22s 50ms/step - loss: 0.0967 - accuracy: 0.9652 - val_loss: 0.2584 - val_accuracy: 0.9162\n"
     ]
    }
   ],
   "source": [
    "train_log = q_aware_model.fit(train_images, train_labels,\n",
    "    batch_size = 128,\n",
    "    # epochs = 15,\n",
    "    epochs = 1,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.9082\n",
      "Test accuracy :  90.82%\n"
     ]
    }
   ],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_9_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_q3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_q3\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save quantized model\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q3\"\n",
    "# q_aware_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2993 - accuracy: 0.9082\n",
      "Test accuracy :  90.82%\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q3\"\n",
    "# with tfmot.quantization.keras.quantize_scope():\n",
    "#     q_aware_model = tf.keras.models.load_model(save_path)\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer :  0 quantize_layer_3  - params :  3\n",
      "Layer :  1 quant_conv2d  - params :  3\n",
      "Layer :  2 quant_re_lu  - params :  3\n",
      "Layer :  3 quant_max_pooling2d  - params :  1\n",
      "Layer :  4 quant_conv2d_1  - params :  3\n",
      "Layer :  5 quant_re_lu_1  - params :  3\n",
      "Layer :  6 quant_max_pooling2d_1  - params :  1\n",
      "Layer :  7 quant_conv2d_2  - params :  3\n",
      "Layer :  8 quant_re_lu_2  - params :  3\n",
      "Layer :  9 quant_max_pooling2d_2  - params :  1\n",
      "Layer :  10 quant_flatten  - params :  1\n",
      "Layer :  11 quant_dense  - params :  7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(q_aware_model.layers)):\n",
    "    print(\"Layer : \", i, q_aware_model.layers[i].name,\" - params : \", len(q_aware_model.layers[i].variables))#, len(q_aware_model.layers[i]), \"Weights len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_layer.QuantizeLayer'>\n",
      "Layer 0 quantize_layer_4\n",
      "[('quantize_layer_4/quantize_layer_4_min:0', TensorShape([])), ('quantize_layer_4/quantize_layer_4_max:0', TensorShape([])), ('quantize_layer_4/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 1 quant_conv2d_9\n",
      "[('conv2d_9/kernel:0', TensorShape([5, 5, 1, 32])), ('conv2d_9/bias:0', TensorShape([32])), ('quant_conv2d_9/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 2 quant_re_lu_9\n",
      "[('quant_re_lu_9/optimizer_step:0', TensorShape([])), ('quant_re_lu_9/output_min:0', TensorShape([])), ('quant_re_lu_9/output_max:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 3 quant_max_pooling2d_9\n",
      "[('quant_max_pooling2d_9/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 4 quant_conv2d_10\n",
      "[('conv2d_10/kernel:0', TensorShape([5, 5, 32, 64])), ('conv2d_10/bias:0', TensorShape([64])), ('quant_conv2d_10/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 5 quant_re_lu_10\n",
      "[('quant_re_lu_10/optimizer_step:0', TensorShape([])), ('quant_re_lu_10/output_min:0', TensorShape([])), ('quant_re_lu_10/output_max:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 6 quant_max_pooling2d_10\n",
      "[('quant_max_pooling2d_10/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 7 quant_conv2d_11\n",
      "[('conv2d_11/kernel:0', TensorShape([3, 3, 64, 96])), ('conv2d_11/bias:0', TensorShape([96])), ('quant_conv2d_11/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 8 quant_re_lu_11\n",
      "[('quant_re_lu_11/optimizer_step:0', TensorShape([])), ('quant_re_lu_11/output_min:0', TensorShape([])), ('quant_re_lu_11/output_max:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 9 quant_max_pooling2d_11\n",
      "[('quant_max_pooling2d_11/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 10 quant_flatten_3\n",
      "[('quant_flatten_3/optimizer_step:0', TensorShape([]))]\n",
      "Type :  <class 'tensorflow_model_optimization.python.core.quantization.keras.quantize_wrapper.QuantizeWrapperV2'>\n",
      "Layer 11 quant_dense_3\n",
      "[('dense_3/kernel:0', TensorShape([96, 10])), ('dense_3/bias:0', TensorShape([10])), ('quant_dense_3/optimizer_step:0', TensorShape([])), ('quant_dense_3/kernel_min:0', TensorShape([])), ('quant_dense_3/kernel_max:0', TensorShape([])), ('quant_dense_3/pre_activation_min:0', TensorShape([])), ('quant_dense_3/pre_activation_max:0', TensorShape([]))]\n"
     ]
    }
   ],
   "source": [
    "for lay in range(len(q_aware_model.layers)):\n",
    "    # print(\"Type : \", type(q_aware_model.layers[lay]))\n",
    "    print(\"Layer\", lay, q_aware_model.layers[lay].name)\n",
    "    print([(q_aware_model.layers[lay].variables[j].name, q_aware_model.layers[lay].variables[j].shape) for j in range(len(q_aware_model.layers[lay].variables))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 _trainable_weights\n",
      "0 _non_trainable_weights\n",
      "0 _initial_weights\n",
      "0 _captured_weight_regularizer\n",
      "0 quantizer\n",
      "0 quantizer_vars\n",
      "1 _trainable_weights\n",
      "1 _non_trainable_weights\n",
      "1 _initial_weights\n",
      "1 _captured_weight_regularizer\n",
      "1 quantize_config\n",
      "1 _weight_vars\n",
      "1 _quantize_activations\n",
      "1 _output_quantizers\n",
      "2 _trainable_weights\n",
      "2 _non_trainable_weights\n",
      "2 _initial_weights\n",
      "2 _captured_weight_regularizer\n",
      "2 quantize_config\n",
      "2 _weight_vars\n",
      "2 _quantize_activations\n",
      "2 _output_quantizers\n",
      "2 _output_quantizer_vars\n",
      "3 _trainable_weights\n",
      "3 _non_trainable_weights\n",
      "3 _initial_weights\n",
      "3 _captured_weight_regularizer\n",
      "3 quantize_config\n",
      "3 _weight_vars\n",
      "3 _quantize_activations\n",
      "3 _output_quantizers\n",
      "4 _trainable_weights\n",
      "4 _non_trainable_weights\n",
      "4 _initial_weights\n",
      "4 _captured_weight_regularizer\n",
      "4 quantize_config\n",
      "4 _weight_vars\n",
      "4 _quantize_activations\n",
      "4 _output_quantizers\n",
      "5 _trainable_weights\n",
      "5 _non_trainable_weights\n",
      "5 _initial_weights\n",
      "5 _captured_weight_regularizer\n",
      "5 quantize_config\n",
      "5 _weight_vars\n",
      "5 _quantize_activations\n",
      "5 _output_quantizers\n",
      "5 _output_quantizer_vars\n",
      "6 _trainable_weights\n",
      "6 _non_trainable_weights\n",
      "6 _initial_weights\n",
      "6 _captured_weight_regularizer\n",
      "6 quantize_config\n",
      "6 _weight_vars\n",
      "6 _quantize_activations\n",
      "6 _output_quantizers\n",
      "7 _trainable_weights\n",
      "7 _non_trainable_weights\n",
      "7 _initial_weights\n",
      "7 _captured_weight_regularizer\n",
      "7 quantize_config\n",
      "7 _weight_vars\n",
      "7 _quantize_activations\n",
      "7 _output_quantizers\n",
      "8 _trainable_weights\n",
      "8 _non_trainable_weights\n",
      "8 _initial_weights\n",
      "8 _captured_weight_regularizer\n",
      "8 quantize_config\n",
      "8 _weight_vars\n",
      "8 _quantize_activations\n",
      "8 _output_quantizers\n",
      "8 _output_quantizer_vars\n",
      "9 _trainable_weights\n",
      "9 _non_trainable_weights\n",
      "9 _initial_weights\n",
      "9 _captured_weight_regularizer\n",
      "9 quantize_config\n",
      "9 _weight_vars\n",
      "9 _quantize_activations\n",
      "9 _output_quantizers\n",
      "10 _trainable_weights\n",
      "10 _non_trainable_weights\n",
      "10 _initial_weights\n",
      "10 _captured_weight_regularizer\n",
      "10 quantize_config\n",
      "10 _weight_vars\n",
      "10 _quantize_activations\n",
      "10 _output_quantizers\n",
      "11 _trainable_weights\n",
      "11 _non_trainable_weights\n",
      "11 _initial_weights\n",
      "11 _captured_weight_regularizer\n",
      "11 quantize_config\n",
      "11 _weight_vars\n",
      "11 _quantize_activations\n",
      "11 _output_quantizers\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    for elem in vars(layer):\n",
    "        if \"quant\" in elem or \"kern\" in elem or \"weight\" in elem or \"var\" in elem or \"bias\" in elem:\n",
    "            print(i, elem)\n",
    "        # if elem == '_output_quantizer_vars':\n",
    "        #     print(i, layer._output_quantizer_vars)\n",
    "        # if elem == '_weight_vars':\n",
    "        #     print(i, layer._weight_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T Lite Model Values\n",
      "[[[-0.01541245  0.00880711  0.09247467 -0.11229067  0.019816  ]\n",
      "  [ 0.01100889  0.15412445  0.20696712  0.12770312 -0.07045689]\n",
      "  [-0.14531734 -0.27962579 -0.2289849   0.1299049  -0.21797601]\n",
      "  [ 0.10788712  0.11229067 -0.01761422  0.01761422  0.24219557]\n",
      "  [ 0.05284267  0.04403556  0.019816   -0.08146578  0.00660533]]]\n",
      "Q Aware\n",
      "[[[-0.01472886]\n",
      "  [ 0.01095581]\n",
      "  [-0.14489803]\n",
      "  [ 0.10731277]\n",
      "  [ 0.05341939]]\n",
      "\n",
      " [[ 0.00825399]\n",
      "  [ 0.15507933]\n",
      "  [-0.2796258 ]\n",
      "  [ 0.11221164]\n",
      "  [ 0.0431769 ]]\n",
      "\n",
      " [[ 0.09138181]\n",
      "  [ 0.20608759]\n",
      "  [-0.22992744]\n",
      "  [-0.01802453]\n",
      "  [ 0.02010153]]\n",
      "\n",
      " [[-0.11331234]\n",
      "  [ 0.12767641]\n",
      "  [ 0.12989913]\n",
      "  [ 0.016807  ]\n",
      "  [-0.08187915]]\n",
      "\n",
      " [[ 0.02014185]\n",
      "  [-0.06991023]\n",
      "  [-0.21795177]\n",
      "  [ 0.2419035 ]\n",
      "  [ 0.00760387]]]\n"
     ]
    }
   ],
   "source": [
    "np.max(q_aware_model.layers[1].variables[0])\n",
    "np.min(q_aware_model.layers[1].variables[0])\n",
    "q_aware_model.layers[1].__dict__.keys()\n",
    "# q_aware_model.layers[1].get_config()\n",
    "q_aware_model.layers[1]._output_quantizers\n",
    "tflite_weights = np.load('tensor-conv-1.npy')\n",
    "print(\"T Lite Model Values\")\n",
    "print( 0.002201777882874012*tflite_weights.T[:5,:5,:,0])\n",
    "print(\"Q Aware\")\n",
    "print(q_aware_model.layers[1].variables[0][:5,:5,:,0].numpy().reshape(5,5,1))\n",
    "# tf.__version__\n",
    "# tfmot.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model weights\n",
      "[[ 0.28528264 -0.5762946  -0.19295678 -0.45415172 -0.35194117]\n",
      " [ 0.20125131 -0.04038209  0.19163042 -0.22182827 -0.21663167]\n",
      " [-0.5341834   0.06868612 -0.14901407  0.10804179  0.19337347]\n",
      " [ 0.2388118   0.047177    0.0628055  -0.40097913  0.2185235 ]\n",
      " [-0.09959683 -0.06364337  0.26062194 -0.00146686  0.04848435]]\n",
      "Manual Quantized values\n",
      "[[ 47. -94. -31. -74. -57.]\n",
      " [ 33.  -7.  31. -36. -35.]\n",
      " [-87.  11. -24.  18.  32.]\n",
      " [ 39.   8.  10. -65.  36.]\n",
      " [-16. -10.  43.   0.   8.]]\n",
      "New fake quantized\n",
      "tf.Tensor(\n",
      "[[ 0.28816587 -0.57633173 -0.19006686 -0.453708   -0.34947777]\n",
      " [ 0.20232923 -0.04291832  0.19006686 -0.2207228  -0.21459161]\n",
      " [-0.5334134   0.06744308 -0.14714853  0.1103614   0.19619805]\n",
      " [ 0.23911637  0.04904951  0.06131189 -0.3985273   0.2207228 ]\n",
      " [-0.09809902 -0.06131189  0.26364112  0.          0.04904951]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bit_width = 8\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            quantized_and_dequantized = quantizer(weight, training = False, weights = quantizer_vars)\n",
    "            # print(quantized_and_dequantized)\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "            new_quantized_and_dequantized = tf.quantization.fake_quant_with_min_max_vars(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized\")\n",
    "            # print(min_var)\n",
    "            # print(max_var)\n",
    "            # print(weight)\n",
    "            # print(type(quantizer))\n",
    "            # print(type(quantizer_vars))\n",
    "            # print(layer._weight_vars[0][0])\n",
    "            # print(layer._weight_vars[0][1])\n",
    "            # print(layer._weight_vars[0][2])\n",
    "            # print(type(quantized_and_dequantized))\n",
    "            # quantized = dequantize(quantize_and_dequantized, min_var, max_var, quantizer)\n",
    "            quantized = np.round(quantized_and_dequantized / max_var * (2**(bit_width-1)-1))\n",
    "            # new_quantized = tf.quantization.fake_quant_with_min_max_vars_per_channel(weight, min_var*np.ones(10), max_var*np.ones(10), bit_width, narrow_range = True, name = \"New_quantized\")\n",
    "# Values of weight variable and q_aware_model are the same\n",
    "# print(weight[:5,:5])\n",
    "print(\"Quantized model weights\")\n",
    "print(q_aware_model.layers[11].get_weights()[0][:5,:5])\n",
    "\n",
    "# print(\"Quantizer num_bits : \", quantizer.num_bits)\n",
    "# print(\"Quantizer per_axis : \", quantizer.per_axis)\n",
    "# print(\"Quantizer symmetric : \", quantizer.symmetric)\n",
    "# print(\"Quantizer narrow_range : \", quantizer.narrow_range)\n",
    "\n",
    "# print(\"Fake Quantized values\")\n",
    "# print(quantized_and_dequantized[:5,:5])\n",
    "print(\"Manual Quantized values\")\n",
    "print(quantized[:5,:5])\n",
    "# tflite_weights = np.load('tensor-dense-3.npy')\n",
    "# print(\"T Lite Model Values\")\n",
    "# print(tflite_weights.T[:5,:5])\n",
    "\n",
    "print(\"New fake quantized\")\n",
    "print(new_quantized_and_dequantized[:5,:5])\n",
    "# print(tf.math.reduce_max(new_quantized_and_dequantized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale :  0.0061311890759806\n",
      "Self quantized : \n",
      "[[ 0.28816587 -0.57633173 -0.19006686 -0.453708   -0.34947777]\n",
      " [ 0.20232923 -0.04291832  0.19006686 -0.2207228  -0.21459161]\n",
      " [-0.5334134   0.06744308 -0.14714853  0.1103614   0.19619805]\n",
      " [ 0.23911637  0.04904951  0.06131189 -0.3985273   0.2207228 ]\n",
      " [-0.09809902 -0.06131189  0.26364112 -0.          0.04904951]]\n",
      "New quantized\n",
      "[[ 47. -94. -31. -74. -57.]\n",
      " [ 33.  -7.  31. -36. -35.]\n",
      " [-87.  11. -24.  18.  32.]\n",
      " [ 39.   8.  10. -65.  36.]\n",
      " [-16. -10.  43.   0.   8.]]\n"
     ]
    }
   ],
   "source": [
    "def quantize_function(input, min_var, max_var, bits, narrow_range = False):\n",
    "    # Very important\n",
    "    if not narrow_range:\n",
    "        scale = (max_var - min_var) / (2**bits - 1)\n",
    "    else:\n",
    "        scale = (max_var - min_var) / (2**bits - 2)\n",
    "    min_adj = scale * round(min_var / scale)\n",
    "    max_adj = max_var + min_adj - min_var\n",
    "    print(\"Scale : \", scale)\n",
    "    # print(\"Min adjusted : \", min_adj)\n",
    "    # print(\"Max adjusted : \", max_adj)\n",
    "    # print(\"Unadjusted min\", min_var)\n",
    "    # print(\"Unadjusted max\", max_var)\n",
    "    return scale * np.round(input / scale)\n",
    "\n",
    "self_quantized = quantize_function(q_aware_model.layers[11].get_weights()[0], min_var.numpy(), max_var.numpy(), bit_width, narrow_range = True)\n",
    "print(\"Self quantized : \")\n",
    "print(self_quantized[:5,:5])\n",
    "new_quantized = np.round(new_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "print(\"New quantized\")\n",
    "print(new_quantized[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10057997610054764\n"
     ]
    }
   ],
   "source": [
    "bits = 8\n",
    "mi = q_aware_model.layers[11].variables[-2].numpy()\n",
    "ma = q_aware_model.layers[11].variables[-1].numpy()\n",
    "scale = (ma - mi) / (2**bits - 1)\n",
    "# foo = scale * np.round(input / scale)\n",
    "print(scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15242569\n",
      "-0.15242569\n",
      "-0.15242569\n",
      "[<tf.Variable 'quant_dense_3/pre_activation_min:0' shape=() dtype=float32, numpy=-14.7027>, <tf.Variable 'quant_dense_3/pre_activation_max:0' shape=() dtype=float32, numpy=10.945194>]\n"
     ]
    }
   ],
   "source": [
    "pos = (41,9)\n",
    "print(quantized_and_dequantized[pos].numpy())\n",
    "print(new_quantized_and_dequantized[pos].numpy())\n",
    "print(self_quantized[pos])\n",
    "\n",
    "\n",
    "# print(\"Other variables stored in last layer\")\n",
    "print(q_aware_model.layers[11].variables[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_re_lu_9\n",
      "[<tf.Variable 'quant_re_lu_9/optimizer_step:0' shape=() dtype=int32, numpy=-1>, <tf.Variable 'quant_re_lu_9/output_min:0' shape=() dtype=float32, numpy=-3.9335735>, <tf.Variable 'quant_re_lu_9/output_max:0' shape=() dtype=float32, numpy=4.5417123>]\n",
      "Scale :  0.0332364138434915\n",
      "0.0332364138434915\n"
     ]
    }
   ],
   "source": [
    "l = 2\n",
    "print(q_aware_model.layers[l].name)\n",
    "# print(len(q_aware_model.layers[l].variables))\n",
    "print(q_aware_model.layers[l].variables)\n",
    "bits = 8\n",
    "narrow_range = False\n",
    "min_var = q_aware_model.layers[l].variables[1].numpy()\n",
    "max_var = q_aware_model.layers[l].variables[2].numpy()\n",
    "# print(max(q_aware_model.layers[l].variables[1]).numpy())\n",
    "# print(min(q_aware_model.layers[l].variables[1]).numpy())\n",
    "# out = quantize_function(q_aware_model.layers[l].variables[1], min_var, max_var, bits, narrow_range)\n",
    "if not narrow_range:\n",
    "    scale = (max_var - min_var) / (2**bits - 1)\n",
    "else:\n",
    "    scale = (max_var - min_var) / (2**bits - 2)\n",
    "min_adj = scale * round(min_var / scale)\n",
    "max_adj = max_var + min_adj - min_var\n",
    "print(\"Scale : \", scale)\n",
    "# print(\"Min adjusted : \", min_adj)\n",
    "# print(\"Max adjusted : \", max_adj)\n",
    "# print(\"Unadjusted min\", min_var)\n",
    "# print(\"Unadjusted max\", max_var)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of q aware model\n",
      "['activity_regularizer', 'add', 'add_loss', 'add_metric', 'add_update', 'add_variable', 'add_weight', 'build', 'built', 'call', 'compile', 'compiled_loss', 'compiled_metrics', 'compute_dtype', 'compute_loss', 'compute_mask', 'compute_metrics', 'compute_output_shape', 'compute_output_signature', 'count_params', 'distribute_reduction_method', 'distribute_strategy', 'dtype', 'dtype_policy', 'dynamic', 'evaluate', 'evaluate_generator', 'finalize_state', 'fit', 'fit_generator', 'from_config', 'get_config', 'get_input_at', 'get_input_mask_at', 'get_input_shape_at', 'get_layer', 'get_metrics_result', 'get_output_at', 'get_output_mask_at', 'get_output_shape_at', 'get_weight_paths', 'get_weights', 'history', 'inbound_nodes', 'input', 'input_mask', 'input_names', 'input_shape', 'input_spec', 'inputs', 'layers', 'load_weights', 'loss', 'losses', 'make_predict_function', 'make_test_function', 'make_train_function', 'metrics', 'metrics_names', 'name', 'name_scope', 'non_trainable_variables', 'non_trainable_weights', 'optimizer', 'outbound_nodes', 'output', 'output_mask', 'output_names', 'output_shape', 'outputs', 'pop', 'predict', 'predict_function', 'predict_generator', 'predict_on_batch', 'predict_step', 'reset_metrics', 'reset_states', 'run_eagerly', 'save', 'save_spec', 'save_weights', 'set_weights', 'state_updates', 'stateful', 'stop_training', 'submodules', 'summary', 'supports_masking', 'test_function', 'test_on_batch', 'test_step', 'to_json', 'to_yaml', 'train_function', 'train_on_batch', 'train_step', 'train_tf_function', 'trainable', 'trainable_variables', 'trainable_weights', 'updates', 'variable_dtype', 'variables', 'weights', 'with_name_scope']\n",
      "['_SCALAR_UPRANKING_ON', '_TF_MODULE_IGNORED_PROPERTIES', '__annotations__', '__call__', '__class__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_activity_regularizer', '_add_trackable', '_add_trackable_child', '_add_variable_with_custom_getter', '_assert_compile_was_called', '_assert_weights_created', '_auto_get_config', '_auto_track_sub_layers', '_autocast', '_autographed_call', '_base_model_initialized', '_build_graph_network_for_inferred_shape', '_build_input_shape', '_call_spec', '_callable_losses', '_captured_weight_regularizer', '_cast_single_input', '_check_call_args', '_check_sample_weight_warning', '_checkpoint', '_checkpoint_dependencies', '_clear_losses', '_cluster_coordinator', '_compile_config', '_compile_from_config', '_compile_was_called', '_compiled_trainable_state', '_compute_dtype', '_compute_dtype_object', '_compute_output_and_mask_jointly', '_compute_tensor_usage_count', '_configure_steps_per_execution', '_conform_to_reference_input', '_created_nodes', '_dedup_weights', '_deferred_dependencies', '_delete_tracking', '_deserialization_dependencies', '_deserialize_from_proto', '_distribute_reduction_method', '_distribution_strategy', '_dtype', '_dtype_policy', '_dynamic', '_eager_losses', '_enable_dict_to_input_mapping', '_expects_mask_arg', '_expects_training_arg', '_export_to_saved_model_graph', '_feed_input_names', '_feed_input_shapes', '_feed_inputs', '_flatten', '_flatten_layers', '_flatten_modules', '_flatten_to_reference_inputs', '_functional_construction_call', '_gather_children_attribute', '_gather_saveables_for_checkpoint', '_get_callback_model', '_get_cell_name', '_get_compile_args', '_get_existing_metric', '_get_input_masks', '_get_node_attribute_at_index', '_get_optimizer', '_get_save_spec', '_get_trainable_state', '_get_unnested_name_scope', '_graph_initialized', '_graph_network_add_loss', '_graph_network_add_metric', '_handle_activity_regularization', '_handle_deferred_dependencies', '_handle_deferred_layer_dependencies', '_handle_weight_regularization', '_has_explicit_input_shape', '_in_multi_worker_mode', '_inbound_nodes', '_inbound_nodes_value', '_infer_output_signature', '_inferred_input_shape', '_init_batch_counters', '_init_call_fn_args', '_init_graph_network', '_init_set_name', '_initial_weights', '_input_coordinates', '_input_dtype', '_input_layers', '_input_spec', '_insert_layers', '_instrument_layer_creation', '_instrumented_keras_api', '_instrumented_keras_layer_class', '_instrumented_keras_model_class', '_is_compiled', '_is_graph_network', '_is_layer', '_is_layer_name_unique', '_is_model_for_instrumentation', '_jit_compile', '_keras_api_names', '_keras_api_names_v1', '_keras_tensor_symbolic_call', '_layer_call_argspecs', '_layer_checkpoint_dependencies', '_layout_map', '_load_own_variables', '_lookup_dependency', '_losses', '_map_resources', '_maybe_build', '_maybe_cast_inputs', '_maybe_create_attribute', '_maybe_initialize_trackable', '_maybe_load_initial_counters_from_ckpt', '_metrics', '_metrics_lock', '_must_restore_from_config', '_name', '_name_based_attribute_restore', '_name_based_restores', '_name_scope', '_name_scope_on_declaration', '_nested_inputs', '_nested_outputs', '_network_nodes', '_no_dependency', '_nodes_by_depth', '_non_trainable_weights', '_obj_reference_counts', '_obj_reference_counts_dict', '_object_identifier', '_outbound_nodes', '_outbound_nodes_value', '_output_coordinates', '_output_layers', '_output_mask_cache', '_output_shape_cache', '_output_tensor_cache', '_predict_counter', '_preload_simple_restoration', '_preserve_input_structure_in_config', '_reset_compile_cache', '_restore_from_tensors', '_run_eagerly', '_run_internal_graph', '_save_experimental', '_save_own_variables', '_saved_model_arg_spec', '_saved_model_inputs_spec', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_tracked_trackables', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_serialize_to_proto', '_serialize_to_tensors', '_set_connectivity_metadata', '_set_dtype_policy', '_set_inputs', '_set_mask_keras_history_checked', '_set_mask_metadata', '_set_output_names', '_set_save_spec', '_set_trainable_state', '_set_training_mode', '_setattr_tracking', '_should_cast_single_input', '_should_compute_mask', '_should_eval', '_stateful', '_steps_per_execution', '_supports_masking', '_tensor_usage_count', '_test_counter', '_tf_api_names', '_tf_api_names_v1', '_thread_local', '_track_trackable', '_track_variable', '_track_variables', '_trackable_children', '_trackable_saved_model_saver', '_tracking_metadata', '_train_counter', '_trainable', '_trainable_weights', '_training_state', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_undeduplicated_weights', '_update_trackables', '_update_uid', '_updated_config', '_updates', '_use_input_spec_as_call_signature', '_use_legacy_deferred_behavior', '_validate_and_get_metrics_result', '_validate_compile', '_validate_graph_inputs_and_outputs', '_validate_target_and_loss']\n"
     ]
    }
   ],
   "source": [
    "print(\"Elements of q aware model\")\n",
    "print([elem for elem in dir(q_aware_model) if not elem.startswith('_')])\n",
    "print([elem for elem in dir(q_aware_model) if elem.startswith('_')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of layer  11 of q aware model\n",
      "['activity_regularizer', 'add_loss', 'add_metric', 'add_update', 'add_variable', 'add_weight', 'build', 'built', 'call', 'compute_dtype', 'compute_mask', 'compute_output_shape', 'compute_output_signature', 'count_params', 'dtype', 'dtype_policy', 'dynamic', 'finalize_state', 'from_config', 'get_config', 'get_input_at', 'get_input_mask_at', 'get_input_shape_at', 'get_output_at', 'get_output_mask_at', 'get_output_shape_at', 'get_weights', 'inbound_nodes', 'input', 'input_mask', 'input_shape', 'input_spec', 'layer', 'losses', 'metrics', 'name', 'name_scope', 'non_trainable_variables', 'non_trainable_weights', 'optimizer_step', 'outbound_nodes', 'output', 'output_mask', 'output_shape', 'quantize_config', 'set_weights', 'stateful', 'submodules', 'supports_masking', 'trainable', 'trainable_variables', 'trainable_weights', 'updates', 'variable_dtype', 'variables', 'weights', 'with_name_scope']\n",
      "['_TF_MODULE_IGNORED_PROPERTIES', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_activity_regularizer', '_add_trackable', '_add_trackable_child', '_add_variable_with_custom_getter', '_auto_get_config', '_auto_track_sub_layers', '_autocast', '_autographed_call', '_build_input_shape', '_call_spec', '_callable_losses', '_captured_weight_regularizer', '_cast_single_input', '_checkpoint_dependencies', '_clear_losses', '_compute_dtype', '_compute_dtype_object', '_dedup_weights', '_deferred_dependencies', '_delete_tracking', '_deserialization_dependencies', '_deserialize_from_proto', '_dtype', '_dtype_policy', '_dynamic', '_eager_losses', '_expects_mask_arg', '_expects_training_arg', '_export_to_saved_model_graph', '_flatten', '_flatten_layers', '_flatten_modules', '_functional_construction_call', '_gather_children_attribute', '_gather_saveables_for_checkpoint', '_get_cell_name', '_get_existing_metric', '_get_input_masks', '_get_node_attribute_at_index', '_get_save_spec', '_get_trainable_state', '_get_unnested_name_scope', '_handle_activity_regularization', '_handle_deferred_dependencies', '_handle_weight_regularization', '_inbound_nodes', '_inbound_nodes_value', '_infer_output_signature', '_init_call_fn_args', '_init_set_name', '_initial_weights', '_input_spec', '_instrument_layer_creation', '_instrumented_keras_api', '_instrumented_keras_layer_class', '_instrumented_keras_model_class', '_is_layer', '_keras_api_names', '_keras_api_names_v1', '_keras_tensor_symbolic_call', '_load_own_variables', '_lookup_dependency', '_losses', '_make_layer_name', '_make_quantizer_fn', '_map_resources', '_maybe_build', '_maybe_cast_inputs', '_maybe_create_attribute', '_maybe_initialize_trackable', '_metrics', '_metrics_lock', '_must_restore_from_config', '_name', '_name_based_attribute_restore', '_name_based_restores', '_name_scope', '_name_scope_on_declaration', '_no_dependency', '_non_trainable_weights', '_obj_reference_counts', '_obj_reference_counts_dict', '_object_identifier', '_outbound_nodes', '_outbound_nodes_value', '_output_quantizers', '_preload_simple_restoration', '_preserve_input_structure_in_config', '_quantize_activations', '_restore_from_tensors', '_save_own_variables', '_saved_model_arg_spec', '_saved_model_inputs_spec', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_tracked_trackables', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_serialize_to_proto', '_serialize_to_tensors', '_set_connectivity_metadata', '_set_dtype_policy', '_set_mask_keras_history_checked', '_set_mask_metadata', '_set_save_spec', '_set_trainable_state', '_set_training_mode', '_setattr_tracking', '_should_cast_single_input', '_stateful', '_supports_masking', '_tf_api_names', '_tf_api_names_v1', '_thread_local', '_track_trackable', '_track_variable', '_track_variables', '_trackable_children', '_trackable_saved_model_saver', '_tracking_metadata', '_trainable', '_trainable_weights', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_update_trackables', '_update_uid', '_updates', '_use_input_spec_as_call_signature', '_weight_name', '_weight_vars']\n"
     ]
    }
   ],
   "source": [
    "l = 11\n",
    "print(\"Elements of layer \", l, \"of q aware model\")\n",
    "print([elem for elem in dir(q_aware_model.layers[l]) if not elem.startswith('_')])\n",
    "print([elem for elem in dir(q_aware_model.layers[l]) if elem.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_dense_3\n",
      "{'name': 'quant_dense_3', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': {'class_name': 'QuantizeAwareActivation', 'config': {'activation': 'softmax'}}, 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, 'quantize_config': {'class_name': 'Default8BitQuantizeConfig', 'config': {'weight_attrs': ['kernel'], 'activation_attrs': ['activation'], 'quantize_output': False}}}\n"
     ]
    }
   ],
   "source": [
    "l = 11\n",
    "print(q_aware_model.layers[l].name)\n",
    "print(q_aware_model.layers[l].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', 'activation_attrs', 'activation_quantizer', 'from_config', 'get_activations_and_quantizers', 'get_config', 'get_output_quantizers', 'get_weights_and_quantizers', 'quantize_output', 'set_quantize_activations', 'set_quantize_weights', 'weight_attrs', 'weight_quantizer']\n",
      "<class 'tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig'>\n",
      "Type\n",
      "{'weight_attrs': ['kernel'], 'activation_attrs': ['activation'], 'quantize_output': False}\n",
      "<tensorflow_model_optimization.python.core.quantization.keras.quantizers.MovingAverageQuantizer object at 0x000001FD570C5F30>\n"
     ]
    }
   ],
   "source": [
    "l = 11\n",
    "print(dir(q_aware_model.layers[l].quantize_config))\n",
    "print(type(q_aware_model.layers[l].quantize_config))\n",
    "conf : tfmot.quantization.keras.default_8bit = q_aware_model.layers[l].quantize_config\n",
    "print(\"Type\")\n",
    "print(q_aware_model.layers[l].quantize_config.get_config())\n",
    "print(q_aware_model.layers[l].quantize_config.activation_quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_conv2d_9\n",
      "tf.Tensor(\n",
      "[-0.2834741  -0.0156017   0.03915993  0.15401286 -0.0032179   0.01683025\n",
      " -0.00186775 -0.01584737 -0.21884577], shape=(9,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "l = 1\n",
    "print(q_aware_model.layers[l].name)\n",
    "# print(q_aware_model.layers[l].quantize_config.get_weights_and_quantizers(model.layers[l]))\n",
    "print(q_aware_model.layers[l].variables[1][-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_9_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpgeabsba2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpgeabsba2\\assets\n",
      "c:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Conversion to TF Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter: tf.lite.Interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    # print(\"Shape : \", test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "    test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "    # print(\"New Shape : \", test_image.shape)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  [ 1 28 28  1]\n",
      "Output Shape:  [ 1 10]\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.908\n",
      "Quant TF test accuracy: 0.9082000255584717\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content = quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Output Shape: \", output_details[0]['shape'])\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "quant_file = 'quant_model_q3.tflite'\n",
    "save_path = save_dir + quant_file\n",
    "# with open(save_path, 'wb') as f:\n",
    "#   f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input index :  4\n",
      "Output index :  4 99.61%\n"
     ]
    }
   ],
   "source": [
    "ind_index = 10\n",
    "test_image = test_images[ind_index]\n",
    "test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "interpreter.invoke()\n",
    "output_array = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(output_array.shape)\n",
    "digit = np.argmax(output_array[0])\n",
    "probability = max(output_array[0])\n",
    "print(\"Input index : \", test_labels[ind_index])\n",
    "print(\"Output index : \", digit, \"{0:.2%}\".format(probability))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 serving_default_conv2d_input:0 (0,) (0,) (1, 28, 28, 1)\n",
      "1 sequential/quant_flatten/Const (0,) (0,) (2,)\n",
      "2 sequential/quant_conv2d/BiasAdd/ReadVariableOp (32,) (32,) (32,)\n",
      "3 sequential/quant_conv2d_1/BiasAdd/ReadVariableOp (64,) (64,) (64,)\n",
      "4 sequential/quant_conv2d_2/BiasAdd/ReadVariableOp (96,) (96,) (96,)\n",
      "5 sequential/quant_conv2d/Conv2D (32,) (32,) (32, 5, 5, 1)\n",
      "6 sequential/quant_conv2d_1/Conv2D (64,) (64,) (64, 5, 5, 32)\n",
      "7 sequential/quant_conv2d_2/Conv2D (96,) (96,) (96, 3, 3, 64)\n",
      "8 sequential/quant_dense/BiasAdd/ReadVariableOp (1,) (1,) (10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor data is null. Run allocate_tensors() first",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m scales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantization_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscales\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m zero_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantization_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(i, tensor_name, scales\u001b[38;5;241m.\u001b[39mshape, zero_points\u001b[38;5;241m.\u001b[39mshape, tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:902\u001b[0m, in \u001b[0;36mInterpreter.tensor.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtensor\u001b[39m(\u001b[39mself\u001b[39m, tensor_index):\n\u001b[0;32m    855\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns function that gives a numpy view of the current tensor buffer.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \n\u001b[0;32m    857\u001b[0m \u001b[39m  This allows reading and writing to this tensors w/o copies. This more\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[39m    but it is not safe to hold the numpy array forever.\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 902\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpreter\u001b[39m.\u001b[39;49mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpreter, tensor_index)\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor data is null. Run allocate_tensors() first"
     ]
    }
   ],
   "source": [
    "# # interpreter.allocate_tensors()\n",
    "# tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "# for dict in tensor_details: \n",
    "#     i = dict['index']\n",
    "#     tensor_name = dict['name']\n",
    "#     scales = dict['quantization_parameters']['scales']\n",
    "#     zero_points = dict['quantization_parameters']['zero_points']\n",
    "#     tensor = interpreter.tensor(i)()\n",
    "    \n",
    "#     print(i, tensor_name, scales.shape, zero_points.shape, tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
