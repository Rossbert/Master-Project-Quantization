{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 96)          55392     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 96)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_last (Dense)          (None, 10)                970       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,458\n",
      "Trainable params: 108,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_functional_model(learning_rate : float) -> tf.keras.Model:\n",
    "    input_layer = tf.keras.layers.Input(shape = (28, 28, 1))\n",
    "    conv_1 = tf.keras.layers.Conv2D(32, 5, use_bias = True, activation = 'relu')(input_layer)\n",
    "    pool_1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_1)\n",
    "    conv_2 = tf.keras.layers.Conv2D(64, 5, use_bias = True, activation = 'relu')(pool_1)\n",
    "    pool_2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_2)\n",
    "    conv_3 = tf.keras.layers.Conv2D(96, 3, use_bias = True, activation = 'relu')(pool_2)\n",
    "    pool_3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(conv_3)\n",
    "    flat_1 = tf.keras.layers.Flatten()(pool_3)\n",
    "    dense_out = tf.keras.layers.Dense(10, activation = 'softmax', name = \"dense_last\")(flat_1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = input_layer, outputs = dense_out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "learning_rate = 0.0003\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "model : tf.keras.Model = get_functional_model(learning_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 2.3032 - accuracy: 0.0969\n",
      "Test accuracy :  9.69%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5400/5400 [==============================] - 29s 5ms/step - loss: 0.5587 - accuracy: 0.7994 - val_loss: 0.4006 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n",
      "5400/5400 [==============================] - 28s 5ms/step - loss: 0.3601 - accuracy: 0.8713 - val_loss: 0.3287 - val_accuracy: 0.8790\n",
      "Epoch 3/10\n",
      "5400/5400 [==============================] - 29s 5ms/step - loss: 0.3028 - accuracy: 0.8903 - val_loss: 0.3122 - val_accuracy: 0.8903\n",
      "Epoch 4/10\n",
      "5400/5400 [==============================] - 30s 6ms/step - loss: 0.2695 - accuracy: 0.9025 - val_loss: 0.2844 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "5400/5400 [==============================] - 29s 5ms/step - loss: 0.2463 - accuracy: 0.9111 - val_loss: 0.2674 - val_accuracy: 0.9042\n",
      "Epoch 6/10\n",
      "5400/5400 [==============================] - 27s 5ms/step - loss: 0.2246 - accuracy: 0.9186 - val_loss: 0.2877 - val_accuracy: 0.8937\n",
      "Epoch 7/10\n",
      "5400/5400 [==============================] - 27s 5ms/step - loss: 0.2077 - accuracy: 0.9255 - val_loss: 0.2525 - val_accuracy: 0.9092\n",
      "Epoch 8/10\n",
      "5400/5400 [==============================] - 30s 6ms/step - loss: 0.1909 - accuracy: 0.9298 - val_loss: 0.2561 - val_accuracy: 0.9058\n",
      "Epoch 9/10\n",
      "5400/5400 [==============================] - 30s 6ms/step - loss: 0.1763 - accuracy: 0.9339 - val_loss: 0.2641 - val_accuracy: 0.9060\n",
      "Epoch 10/10\n",
      "5400/5400 [==============================] - 28s 5ms/step - loss: 0.1637 - accuracy: 0.9416 - val_loss: 0.2534 - val_accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "train_log = model.fit(train_images, train_labels,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.9075\n",
      "Test accuracy :  90.75%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_official_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_official_1\\assets\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_official_1\"\n",
    "# model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.9075\n",
      "Test accuracy :  90.75%\n"
     ]
    }
   ],
   "source": [
    "# Load model_v3\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_v3\"\n",
    "# model = tf.keras.models.load_model(save_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " quantize_layer_2 (QuantizeL  (None, 28, 28, 1)        3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_conv2d_9 (QuantizeWra  (None, 24, 24, 32)       899       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_max_pooling2d_9 (Quan  (None, 12, 12, 32)       1         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_conv2d_10 (QuantizeWr  (None, 8, 8, 64)         51395     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_10 (Qua  (None, 4, 4, 64)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_11 (QuantizeWr  (None, 2, 2, 96)         55587     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_11 (Qua  (None, 1, 1, 96)         1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_flatten_3 (QuantizeWr  (None, 96)               1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dense_last (QuantizeW  (None, 10)               975       \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,863\n",
      "Trainable params: 108,458\n",
      "Non-trainable params: 405\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model = tfmot.quantization.keras.quantize_model(model)\n",
    "q_aware_model.compile(optimizer = 'adam', \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 4.0996 - accuracy: 0.1000\n",
      "Test accuracy :  10.00%\n"
     ]
    }
   ],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 20s 45ms/step - loss: 0.1482 - accuracy: 0.9462 - val_loss: 0.2671 - val_accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "train_log = q_aware_model.fit(train_images, train_labels,\n",
    "    batch_size = 128,\n",
    "    # epochs = 15,\n",
    "    epochs = 1,\n",
    "    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2876 - accuracy: 0.9046\n",
      "Test accuracy :  90.46%\n"
     ]
    }
   ],
   "source": [
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_10_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_q_official_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/model_q_official_1\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save quantized model\n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q_official_1\"\n",
    "# q_aware_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2876 - accuracy: 0.9046\n",
      "Test accuracy :  90.46%\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q_official_1\"\n",
    "q_aware_model : tf.keras.Model\n",
    "# with tfmot.quantization.keras.quantize_scope():\n",
    "#     q_aware_model = tf.keras.models.load_model(save_path)\n",
    "q_aware_test_loss, q_aware_test_acc = q_aware_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy : ', \"{:0.2%}\".format(q_aware_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer :  0 input_4  - params :  0\n",
      "Layer :  1 quantize_layer_2  - params :  3\n",
      "Layer :  2 quant_conv2d_9  - params :  7\n",
      "Layer :  3 quant_max_pooling2d_9  - params :  1\n",
      "Layer :  4 quant_conv2d_10  - params :  7\n",
      "Layer :  5 quant_max_pooling2d_10  - params :  1\n",
      "Layer :  6 quant_conv2d_11  - params :  7\n",
      "Layer :  7 quant_max_pooling2d_11  - params :  1\n",
      "Layer :  8 quant_flatten_3  - params :  1\n",
      "Layer :  9 quant_dense_last  - params :  7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(q_aware_model.layers)):\n",
    "    print(\"Layer : \", i, q_aware_model.layers[i].name,\" - params : \", len(q_aware_model.layers[i].variables))#, len(q_aware_model.layers[i]), \"Weights len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/kernel\n",
      "[[ -34.    9.   41.  -66. -127.]\n",
      " [ -70.    8.   57.   27.  -73.]\n",
      " [   5.   39.  -30.  -17.   33.]\n",
      " [  47.  -23.   -1.  -23.   -1.]\n",
      " [  39.   16.  -19.    4.   12.]]\n",
      "conv2d_1/kernel\n",
      "[[-18. -40. -32.   4.  -3.]\n",
      " [  5. -28. -42.  12.  20.]\n",
      " [ 47. -42. -14. -11.  32.]\n",
      " [ 41. -15.   0. -15.  17.]\n",
      " [ 35. -10.  -4.  17.  25.]]\n",
      "conv2d_2/kernel\n",
      "[[ 69.  51.  -2.]\n",
      " [  2. -98. -63.]\n",
      " [ 67.   5. -44.]]\n",
      "dense_last/kernel\n",
      "[  4.   1.  -6.   6.  -1. -10. -18.  20. -18.  -8.  -1.  -6. -30. -13.\n",
      "  -8.  11.  13.   5. -35. -12. -24. -18.   8.   8.  -4. -27.  18.  15.\n",
      " -46. -23.  21. -42.  19.  12.  12.  -1.   9.  -8.   1.  18.  -6.  13.\n",
      "  -2.  13.   8. -10.  12.  27.   5.  -1.  -5.  -5. -11.  13. -29. -25.\n",
      "  -8.   4.  19.   4. -19. -26.  32.  15. -35. -12.   0.  31.  -8. -25.\n",
      "  10.  21.  14.  14.  -9.   7. -24. -23. -15.  18.   6.  27.  26.  13.\n",
      "   9.  34.   6. -25. -23. -14. -42. -17.  -2.   7. -18.   9.]\n"
     ]
    }
   ],
   "source": [
    "bit_width = 8\n",
    "quantized_and_dequantized = OrderedDict()\n",
    "quantized = OrderedDict()\n",
    "new_quantized_and_dequantized = OrderedDict()\n",
    "new_quantized = OrderedDict()\n",
    "layer_index_list = []\n",
    "keys_list = []\n",
    "\n",
    "layer : tfmot.quantization.keras.QuantizeWrapperV2\n",
    "for i, layer in enumerate(q_aware_model.layers):\n",
    "    quantizer : tfmot.quantization.keras.quantizers.Quantizer\n",
    "    weight : tf.Variable\n",
    "    if hasattr(layer, '_weight_vars'):\n",
    "        for weight, quantizer, quantizer_vars in layer._weight_vars:\n",
    "            min_var = quantizer_vars['min_var']\n",
    "            max_var = quantizer_vars['max_var']\n",
    "\n",
    "            key = weight.name[:-2]\n",
    "            layer_index_list.append(i)\n",
    "            keys_list.append(key)\n",
    "            quantized_and_dequantized[key] = quantizer(inputs = weight, training = False, weights = quantizer_vars)\n",
    "            quantized[key] = np.round(quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "            if \"conv2d\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars_per_channel(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "            elif \"dense\" in layer.name:\n",
    "                new_quantized_and_dequantized[key] = tf.quantization.fake_quant_with_min_max_vars(weight, min_var, max_var, bit_width, narrow_range = True, name = \"New_quantized_\" + str(i))\n",
    "                new_quantized[key] = np.round(new_quantized_and_dequantized[key] / max_var * (2**(bit_width-1)-1))\n",
    "\n",
    "for key in quantized:\n",
    "    # print(\"Fake Quantized\")\n",
    "    print(key)\n",
    "    if \"dense\" not in key:\n",
    "        # print(quantized_and_dequantized[key][:,:,0,0])\n",
    "        print(quantized[key][:,:,0,0])\n",
    "    else:\n",
    "        # print(quantized_and_dequantized[key][:,0])\n",
    "        print(quantized[key][:,0])\n",
    "\n",
    "    # print(\"New Fake Quantized\")\n",
    "    # print(key)\n",
    "    # if \"dense\" not in key:\n",
    "    #     print(new_quantized_and_dequantized[key][:,:,0,0])\n",
    "    #     print(new_quantized[key][:,:,0,0])\n",
    "    # else:\n",
    "    #     print(new_quantized_and_dequantized[key][:,0])\n",
    "    #     print(new_quantized[key][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_9/kernel\n",
      "[[ -20.   67.   38.  127.   26.]\n",
      " [  22.    1.  -76.   67. -103.]\n",
      " [  39.   -7.  -97.   51.  -54.]\n",
      " [ -42.    9.   59.  -26.  -40.]\n",
      " [  23.  -89.  -15.   94.    4.]]\n",
      "conv2d_10/kernel\n",
      "[[-12.   4.  25.   5. -62.]\n",
      " [-13.   8. -11.   4.  12.]\n",
      " [ 21.  20.  12.   2.   2.]\n",
      " [ 30.  16.   6.  41. -32.]\n",
      " [ 22.  24.  10.  27. -25.]]\n",
      "conv2d_11/kernel\n",
      "[[ 29. -45.  47.]\n",
      " [ -3. -35.  30.]\n",
      " [ -8.   4.  26.]]\n",
      "dense_last/kernel\n",
      "[-22.  -8. -25.  -7.  23. -14.   4. -52. -11. -28.   9.   0.  -2.  24.\n",
      "  16. -36.  40. -24.  41.  29. -24.  10.  14.  26. -19. -23.   1. -14.\n",
      "  -6.  32.  39. -39. -20. -46. -27. -20.  33. -45. -24.  -5. -47.  33.\n",
      " -52. -29. -28. -26. -32. -31.   6.  -7.   4.  36. -23.   4. -10. -33.\n",
      " -29.  23.   4. -14.  22.  37. -32. -34. -48.   1. -32.  19. -17. -37.\n",
      " -10. -55. -40. -19.  25. -13. -16.  21. -32.   5. -11.  19. -48.   2.\n",
      "  30.   1.  26. -29.  50.  34.  21.  -8.  29.  -3.  37. -25.]\n"
     ]
    }
   ],
   "source": [
    "def self_quantize_function(input, min_var, max_var, bits, narrow_range = False):\n",
    "    if not narrow_range:\n",
    "        scale = (max_var - min_var) / (2**bits - 1)\n",
    "    else:\n",
    "        scale = (max_var - min_var) / (2**bits - 2)\n",
    "    # min_adj = scale * np.round(min_var / scale)\n",
    "    # max_adj = max_var + min_adj - min_var\n",
    "    # print(\"Scale : \", scale)\n",
    "    return scale * np.round(input / scale)\n",
    "\n",
    "for idx, layer_index in enumerate(layer_index_list):\n",
    "    m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if keys_list[idx] in variable.name}\n",
    "    kernel = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].trainable_variables) if \"kernel\" in variable.name}\n",
    "    min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "    max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "    min_var = m_vars[min_key]\n",
    "    max_var = m_vars[max_key]\n",
    "\n",
    "    kernel_index = 0\n",
    "    self_quantized_and_dequantized = self_quantize_function(q_aware_model.layers[layer_index].trainable_variables[kernel_index], min_var, max_var, bit_width, narrow_range = True)\n",
    "    \n",
    "    print(keys_list[idx])\n",
    "    # print(\"Self Quantized\")\n",
    "    if \"dense\" not in keys_list[idx]:\n",
    "        # print(self_quantized_and_dequantized[:,:,0,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,:,0,0])\n",
    "    else:\n",
    "        # print(self_quantized_and_dequantized[:,0])\n",
    "        self_quantized = np.round(self_quantized_and_dequantized / max_var * (2**(bit_width - 1) - 1))\n",
    "        print(self_quantized[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight_attrs': ['kernel'], 'activation_attrs': ['activation'], 'quantize_output': False}\n",
      "<tensorflow_model_optimization.python.core.quantization.keras.quantizers.MovingAverageQuantizer object at 0x000001F9EB05D570>\n"
     ]
    }
   ],
   "source": [
    "l = 2\n",
    "print(q_aware_model.layers[l].quantize_config.get_config())\n",
    "print(q_aware_model.layers[l].quantize_config.activation_quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_10_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpyawuma0f\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmpyawuma0f\\assets\n",
      "c:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Conversion to TF Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter: tf.lite.Interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    # print(\"Shape : \", test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis = 0).astype(np.float32)\n",
    "    test_image = np.expand_dims(test_image, axis = 3).astype(np.float32)\n",
    "    # print(\"New Shape : \", test_image.shape)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  [ 1 28 28  1]\n",
      "Output Shape:  [ 1 10]\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9046\n",
      "Quant TF test accuracy: 0.9046000242233276\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content = quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Output Shape: \", output_details[0]['shape'])\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./logs/\"\n",
    "quant_file = 'quant_model_q_official_1.tflite'\n",
    "save_path = save_dir + quant_file\n",
    "# with open(save_path, 'wb') as f:\n",
    "#   f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-66\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "def prob_mass_gen(bits : int):\n",
    "    \"\"\" Discrete triangular distribution\n",
    "        - Only a max probability and slope are allowed \"\"\"\n",
    "    values = np.arange(0, bits)\n",
    "    n = len(values)\n",
    "    p_max = 2/n\n",
    "    m_max = p_max/(n - 1)\n",
    "    # Probability calculation\n",
    "    p = p_max * 1.0\n",
    "    m = 2/(n - 1)*(p- 1/n)\n",
    "    probabilities = [p + m*(i - values[-1]) for i in values]\n",
    "    return values, probabilities\n",
    "\n",
    "def random_bit_flipper(value : int):\n",
    "    r\"\"\" All values are in 8 bits, MSB have higher probability of getting flipped\n",
    "        - It is assumed value is a signed 8 bit number \"\"\"\n",
    "    bits, probs = prob_mass_gen(8)\n",
    "    bit_pos = np.random.choice(bits, p = probs)\n",
    "\n",
    "    # print(\"Value\", value, bin(value))\n",
    "\n",
    "    # Negative 2 Complement conversion\n",
    "    if value < 0:\n",
    "        value = (-value ^ 0xFF) + 1\n",
    "\n",
    "    # print(\"Value after 2 complement conversion:\", value, bin(value))\n",
    "\n",
    "    flip_mask = 1 << bit_pos\n",
    "    flipped = value ^ flip_mask\n",
    "    # print(\"Bit to be flipped\", bit_pos)\n",
    "    # print(\"Flipped value\", flipped, bin(flipped))\n",
    "\n",
    "    # Negative back conversion 2 Complement\n",
    "    if flipped >= 128:\n",
    "        flipped = -((flipped ^ 0xFF) + 1)\n",
    "        # print(\"Negative back conversion\", flipped)\n",
    "    return flipped\n",
    "\n",
    "val = np.random.randint(-127,127)\n",
    "print(val)\n",
    "print(random_bit_flipper(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random position 0 0 0 0\n",
      "[[ -20.   67.   38.  127.   26.]\n",
      " [  22.    1.  -76.   67. -103.]\n",
      " [  39.   -7.  -97.   51.  -54.]\n",
      " [ -42.    9.   59.  -26.  -40.]\n",
      " [  23.  -89.  -15.   94.    4.]]\n",
      "-20.0\n",
      "tf.Tensor(\n",
      "[[-0.03571794  0.12105308  0.0683602   0.22875616  0.04659204]\n",
      " [ 0.03975419  0.00167603 -0.13742748  0.12099734 -0.18465865]\n",
      " [ 0.0703144  -0.01184483 -0.17510103  0.09140633 -0.09658822]\n",
      " [-0.07492749  0.01618467  0.10540633 -0.04606877 -0.07135177]\n",
      " [ 0.04229205 -0.16009727 -0.02699903  0.16959691  0.0072944 ]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(-0.03571794, shape=(), dtype=float32)\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "save_dir = \"./logs/\"\n",
    "save_path = save_dir + \"model_q_official_1\"\n",
    "q_aware_copy : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_copy = tf.keras.models.load_model(save_path)\n",
    "\n",
    "# random_channel = np.random.randint(0,32)\n",
    "# random_kernel_x = np.random.randint(0,5)\n",
    "# random_kernel_y = np.random.randint(0,5)\n",
    "random_channel = 0\n",
    "random_kernel_x = 0\n",
    "random_kernel_y = 0\n",
    "idx = 0\n",
    "key = keys_list[idx]\n",
    "layer_index = layer_index_list[idx]\n",
    "kernel_index = 0\n",
    "print(\"Random position\", random_kernel_x, random_kernel_y, 0, random_channel)\n",
    "print(new_quantized[key][:,:,0,random_channel])\n",
    "print(new_quantized[key][random_kernel_x,random_kernel_y,0,random_channel])\n",
    "print(q_aware_copy.layers[layer_index].trainable_variables[kernel_index][:,:,0,random_channel])\n",
    "print(q_aware_copy.layers[layer_index].trainable_variables[kernel_index][random_kernel_x,random_kernel_y,0,random_channel])\n",
    "\n",
    "flipped_kernel_value = random_bit_flipper(int(new_quantized[key][random_kernel_x,random_kernel_y,0,random_channel]))\n",
    "print(flipped_kernel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv2d_9/kernel', 'conv2d_10/kernel', 'conv2d_11/kernel', 'dense_last/kernel']\n",
      "108\n",
      "0.19451098883245874\n",
      "tf.Tensor(-0.03571794, shape=(), dtype=float32)\n",
      "0x1f9fa3a5540\n",
      "tf.Tensor(\n",
      "[[ 0.19451098  0.12105308  0.0683602   0.22875616  0.04659204]\n",
      " [ 0.03975419  0.00167603 -0.13742748  0.12099734 -0.18465865]\n",
      " [ 0.0703144  -0.01184483 -0.17510103  0.09140633 -0.09658822]\n",
      " [-0.07492749  0.01618467  0.10540633 -0.04606877 -0.07135177]\n",
      " [ 0.04229205 -0.16009727 -0.02699903  0.16959691  0.0072944 ]], shape=(5, 5), dtype=float32)\n",
      "0x1f9fa3a5540\n"
     ]
    }
   ],
   "source": [
    "print(keys_list)\n",
    "# idx = key_index_list.index(\"conv2d_9/kernel\")\n",
    "idx = 0\n",
    "layer_index = layer_index_list[idx]\n",
    "kernel_index = 0\n",
    "m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if keys_list[idx] in variable.name}\n",
    "kernel = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].trainable_variables) if \"kernel\" in variable.name}\n",
    "min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "min_var = m_vars[min_key]\n",
    "max_var = m_vars[max_key]\n",
    "\n",
    "print(flipped_kernel_value)\n",
    "self_flipped = flipped_kernel_value * max_var.numpy()[random_channel] / (2**(bit_width - 1) - 1)\n",
    "print(self_flipped)\n",
    "original_val = q_aware_copy.layers[layer_index].trainable_variables[kernel_index][random_kernel_x,random_kernel_y,0,random_channel]\n",
    "print(original_val)\n",
    "update_kernel = q_aware_copy.layers[layer_index].trainable_variables[kernel_index].numpy()\n",
    "update_kernel[random_kernel_x,random_kernel_y,0,random_channel] = self_flipped\n",
    "# update_kernel[random_kernel_x,random_kernel_y,0,random_channel] = original_val.numpy()\n",
    "print(hex(id(q_aware_copy.layers[layer_index].trainable_variables[kernel_index])))\n",
    "q_aware_copy.layers[layer_index].trainable_variables[kernel_index].assign(update_kernel)\n",
    "print(q_aware_copy.layers[layer_index].trainable_variables[kernel_index][:,:,0,random_channel])\n",
    "print(hex(id(q_aware_copy.layers[layer_index].trainable_variables[kernel_index])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_9_layer_call_fn, conv2d_9_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_10_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmptiq_mtw0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rosal\\AppData\\Local\\Temp\\tmptiq_mtw0\\assets\n",
      "c:\\Users\\rosal\\py_master_project\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Conversion to TF Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_copy)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "q_copy_tflite_model = converter.convert()\n",
    "\n",
    "save_dir = \"./logs/\"\n",
    "quant_file = 'quant_model_q_perturbed_1.tflite'\n",
    "save_path = save_dir + quant_file\n",
    "with open(save_path, 'wb') as f:\n",
    "  f.write(q_copy_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  [ 1 28 28  1]\n",
      "Output Shape:  [ 1 10]\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9025\n",
      "Quant TF test accuracy: 0.9046000242233276\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content = q_copy_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Output Shape: \", output_details[0]['shape'])\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "LOAD_PATH_Q_AWARE = \"./model/\" + \"model_q_aware_final_01\"\n",
    "\n",
    "q_aware_model : tf.keras.Model\n",
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    q_aware_model = tf.keras.models.load_model(LOAD_PATH_Q_AWARE)\n",
    "\n",
    "\n",
    "def bit_flipper(value : int, bit_pos : int) -> int:\n",
    "    \"\"\" Random bit flipper \n",
    "    -\n",
    "    Obtains a value and bit position and flips it.\n",
    "    - All values are in 8 bits, MSB have higher probability of getting flipped\n",
    "    - It is assumed value is a signed 8 bit number \"\"\"\n",
    "    # Negative 2 Complement conversion\n",
    "    if value < 0:\n",
    "        value = (-value ^ 0xFF) + 1\n",
    "    flip_mask = 1 << bit_pos\n",
    "    flipped_value = value ^ flip_mask\n",
    "    # Negative back conversion 2 Complement\n",
    "    if flipped_value >= 128:\n",
    "        flipped_value = -((flipped_value ^ 0xFF) + 1)\n",
    "    return flipped_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Performance.csv')\n",
    "position_disrupted_list = []\n",
    "bit_flipped_list = []\n",
    "for d in df['position_disrupted']:\n",
    "    try:\n",
    "        position_disrupted_list.append(ast.literal_eval(d))\n",
    "    except:\n",
    "        position_disrupted_list.append(tuple())\n",
    "for d in df['bit_disrupted']:\n",
    "    try:\n",
    "        bit_flipped_list.append(int(d))\n",
    "    except:\n",
    "        bit_flipped_list.append(-1)\n",
    "\n",
    "out_list = []\n",
    "conv_idx = 0 \n",
    "bit_width = 8\n",
    "key = keys_list[conv_idx]\n",
    "layer_index = layer_index_list[conv_idx]\n",
    "T_VARIABLES_KERNEL_INDEX = 0\n",
    "\n",
    "for i, position in enumerate(position_disrupted_list):\n",
    "    entry = {}\n",
    "    entry['data'] = position\n",
    "    if len(position) > 1:\n",
    "        m_vars = {variable.name: variable for i, variable in enumerate(q_aware_model.layers[layer_index].non_trainable_variables) if keys_list[conv_idx] in variable.name}\n",
    "        min_key = list(key for key in m_vars if \"min\" in key)[0]\n",
    "        max_key = list(key for key in m_vars if \"max\" in key)[0]\n",
    "        min_var = m_vars[min_key]\n",
    "        max_var = m_vars[max_key]\n",
    "        entry['min_var'] = min_var[position[-1]].numpy()\n",
    "        entry['max_var'] = max_var[position[-1]].numpy()\n",
    "        entry['original_weight_value'] = q_aware_model.layers[layer_index].trainable_variables[T_VARIABLES_KERNEL_INDEX][position].numpy()\n",
    "        entry['quantized_value'] = quantized[key][position]\n",
    "        entry['flipped_quantized_value'] = bit_flipper(int(quantized[key][position]), bit_flipped_list[i])\n",
    "        entry['flipped_weight_value'] = entry['flipped_quantized_value'] * max_var.numpy()[position[-1]] / (2**(bit_width - 1) - 1)\n",
    "    else:\n",
    "        entry['min_var'] = None\n",
    "        entry['max_var'] = None\n",
    "        entry['original_weight_value'] = None\n",
    "        entry['quantized_value'] = None\n",
    "        entry['flipped_quantized_value'] = None\n",
    "        entry['flipped_weight_value'] = None\n",
    "    out_list.append(entry)\n",
    "out_df = pd.DataFrame(out_list)\n",
    "out_df.to_csv('Max_Min.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py_master_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b772b08f604b6b43e5a3a606000b08c03a565bb0332f867b1c8863c689a183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
